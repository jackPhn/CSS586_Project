{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f43165f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pathlib\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, BatchNormalization, Dropout, Dense, Activation\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from musiclearn import config\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "088e5c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_dir = pathlib.Path(config.FF_MIDI_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16bddfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of an input sequence\n",
    "SEQUENCE_LENGTH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fdbecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes(midi_dir):\n",
    "    \"\"\" Get all the notes and chords from the midi files in the collection /ff_midi_songs \"\"\"\n",
    "    notes = []\n",
    "    \n",
    "    noteFile_dir = str(midi_dir) + \"/notes\"\n",
    "    \n",
    "    if not os.path.exists(noteFile_dir):\n",
    "        files_dir = str(midi_dir) + \"/*.mid\"\n",
    "        for file in glob.glob(files_dir):\n",
    "            midi = converter.parse(file)\n",
    "\n",
    "            print(\"Parsing %s\" % file)\n",
    "\n",
    "            notes_to_parse = None\n",
    "\n",
    "            try: # file has instrument parts\n",
    "                s2 = instrument.partitionByInstrument(midi)\n",
    "                notes_to_parse = s2.parts[0].recurse()\n",
    "            except: # file has notes in a flat structure\n",
    "                notes_to_parse = midi.flat.notes\n",
    "\n",
    "            for element in notes_to_parse:\n",
    "                if isinstance(element, note.Note):\n",
    "                     notes.append(str(element.pitch))\n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "        # save the features\n",
    "        with open(noteFile_dir, 'wb') as fp:\n",
    "            pickle.dump(notes, fp)\n",
    "    else:\n",
    "        with open(noteFile_dir, 'rb') as fp:\n",
    "            notes = pickle.load(fp)\n",
    "    \n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e716a1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the neural network \"\"\"\n",
    "    sequence_length  = 100\n",
    "    \n",
    "    # get all pitch name\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    \n",
    "    # create a dictionary to map pitches to integers\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "    \n",
    "    network_input = []\n",
    "    network_output = []\n",
    "    \n",
    "    # create input sequences and teh corresponding outputs\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i : i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "        \n",
    "    n_samples = len(network_input)\n",
    "    \n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    network_input = np.reshape(network_input, (n_samples, sequence_length, 1))\n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "    \n",
    "    network_output = keras.utils.to_categorical(network_output)\n",
    "    \n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bdbd1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(network_input, n_vocab):\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
    "        recurrent_dropout=0.3,\n",
    "        return_sequences=True\n",
    "    ))\n",
    "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
    "    model.add(LSTM(512))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f455b810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(notes, epochs = 20, batch_size = 128):\n",
    "    \"\"\" Train a neural network to generate music \"\"\"\n",
    "    # get amount of pitch names\n",
    "    n_vocab = len(set(notes))\n",
    "    \n",
    "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
    "\n",
    "    model = lstm_model(network_input, n_vocab)\n",
    "    \n",
    "    # train the network\n",
    "    filepath = \"saved_weight.hdf5\"\n",
    "    \n",
    "    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath,\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        node='min'\n",
    "    )\n",
    "    \n",
    "    callback_list = [checkpoint_cb]\n",
    "    \n",
    "    model.fit(network_input, network_output, epochs=epochs, batch_size=batch_size, callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9257833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features\n",
    "notes = get_notes(midi_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "802a692b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 100, 512)          1052672   \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 100, 512)          2099200   \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 308)               79156     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 308)               0         \n",
      "=================================================================\n",
      "Total params: 5,464,628\n",
      "Trainable params: 5,463,092\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# test code to output model architecture\n",
    "n_vocab = len(set(notes))\n",
    "network_input, network_output = prepare_sequences(notes, n_vocab)\n",
    "model = lstm_model(network_input, n_vocab)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de435dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 95s 261ms/step - loss: 5.5609\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 91s 260ms/step - loss: 4.7685\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 91s 260ms/step - loss: 4.5786\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 91s 260ms/step - loss: 4.5552\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 90s 258ms/step - loss: 4.5317\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 90s 257ms/step - loss: 4.4951\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 90s 256ms/step - loss: 4.4543\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 90s 256ms/step - loss: 4.4161\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 90s 256ms/step - loss: 4.3506\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 90s 256ms/step - loss: 4.2922\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 90s 256ms/step - loss: 4.2315\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 89s 255ms/step - loss: 4.1783\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 89s 255ms/step - loss: 4.0977\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 89s 255ms/step - loss: 4.0148\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 3.9111\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 3.8255\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 3.7172\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 3.6293\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 3.5220\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 3.4373\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 3.3324\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 3.2313\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 88s 253ms/step - loss: 3.1239\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 3.0500\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 2.9583\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 2.8852\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 2.8071\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 2.7012\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 2.6407\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 2.5542\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 2.4883\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 2.4256\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 2.3302\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 2.2848\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 2.2180\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 2.1483\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 2.0962\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 2.0307\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 1.9693\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 1.9361\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 1.8856\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 1.8140\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 1.7658\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 1.7111\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 1.6624\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 1.6220\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 1.5738\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 1.5445\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 1.5251\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 1.4433\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 1.4143\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 1.3813\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 1.3334\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 1.2936\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 88s 253ms/step - loss: 1.2855\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 1.2224\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 1.1893\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 1.1608\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 1.1228\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 1.1063\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 1.0773\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 1.0505\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 1.0020\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 0.9971\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 0.9546\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 0.9538\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 0.9181\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 0.8947\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 0.8608\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 0.8643\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 0.8364\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 0.8088\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 0.7737\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 0.7739\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 0.7575\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 0.7239\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 0.7302\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 0.7022\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 0.6702\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 0.6626\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 0.6462\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 0.6356\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 0.6202\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 0.6001\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 0.5931\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 0.5754\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 0.5593\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 0.5396\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 0.5405\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 0.5447\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 0.5324\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 0.5132\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 0.5155\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 0.4915\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 0.4812\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 0.4793\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 0.4657\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 89s 254ms/step - loss: 0.4542\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 0.4481\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 89s 253ms/step - loss: 0.4453\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "train_network(notes, 100, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7af26398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences_to_predict(notes, n_vocab):\n",
    "    \"\"\" Prepare the sequences to make prediction \"\"\"\n",
    "    sequence_length  = 100\n",
    "    \n",
    "    # get all pitch name\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    \n",
    "    # create a dictionary to map pitches to integers\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "    \n",
    "    network_input = []\n",
    "    \n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "    \n",
    "    n_samples = len(network_input)\n",
    "    \n",
    "    # reshapre the input\n",
    "    normalized_input = np.reshape(network_input, (n_samples, sequence_length, 1))\n",
    "    # normalize input\n",
    "    normalized_input = normalized_input / float(n_vocab)\n",
    "    \n",
    "    return (network_input, normalized_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06f0a8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(network_input, n_vocab):\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
    "        recurrent_dropout=0.3,\n",
    "        return_sequences=True\n",
    "    ))\n",
    "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
    "    model.add(LSTM(512))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    \n",
    "    model.load_weights(\"saved_weight.hdf5\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60a1c89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_notes(model, network_input, pitchnames, n_vocab):\n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # pick a random sequence from the input as a starting point for the prediction\n",
    "    start = np.random.randint(0, len(network_input)-1)\n",
    "\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    pattern = network_input[start]\n",
    "    prediction_output = []\n",
    "\n",
    "    # generate 500 notes\n",
    "    for note_index in range(500):\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "\n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "\n",
    "        index = np.argmax(prediction)\n",
    "        result = int_to_note[index]\n",
    "        prediction_output.append(result)\n",
    "\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "\n",
    "    return prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27834288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_midi(prediction_output):\n",
    "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
    "        from the notes \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        # pattern is a note\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 0.5\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "\n",
    "    midi_stream.write('midi', fp='test_output_ff.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82c1cd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence():\n",
    "    \"\"\" Generate a midi file \"\"\"\n",
    "    noteFile_dir = str(midi_dir) + \"/notes\"\n",
    "    \n",
    "    # load the notes used to train the model\n",
    "    with open(noteFile_dir, 'rb') as fp:\n",
    "        notes = pickle.load(fp)\n",
    "    \n",
    "    # get all pitch names\n",
    "    pitchnames =  sorted(set(item for item in notes))\n",
    "    # get number of pitches\n",
    "    n_vocab = len(set(notes))\n",
    "    \n",
    "    network_input, normalized_input = prepare_sequences_to_predict(notes, n_vocab)\n",
    "    \n",
    "    # load saved weights\n",
    "    model = load_model(normalized_input, n_vocab)\n",
    "    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)\n",
    "    # make midi file\n",
    "    create_midi(prediction_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc5d1817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "generate_sequence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baf392d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931e23ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc990e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e80ede1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08b434a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a06b04ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Picking one song from MusicNet dataset\n",
    "midi_dir = pathlib.Path(config.MUSICNET_MIDI_DIR)\n",
    "mid_2494 = midi_dir / \"Beethoven\" / \"2494_qt11_1.mid\"\n",
    "#multitrack = pypianoroll.read(mid_2494, resolution=24)\n",
    "\n",
    "midi = converter.parse(mid_2494)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3220b83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<music21.stream.Score 0x7fa5d84d63d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9752bfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_to_parse = None\n",
    "notes =[]\n",
    "\n",
    "try: # file has instrument parts\n",
    "    s2 = instrument.partitionByInstrument(midi)\n",
    "    notes_to_parse = s2.parts[0].recurse()\n",
    "except: # file has notes in a flat structure\n",
    "    notes_to_parse = midi.flat.notes\n",
    "\n",
    "for element in notes_to_parse:\n",
    "    if isinstance(element, note.Note):\n",
    "        notes.append(str(element.pitch))\n",
    "    elif isinstance(element, chord.Chord):\n",
    "        notes.append('.'.join(str(n) for n in element.normalOrder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "496ed204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F4',\n",
       " 'F4',\n",
       " 'G4',\n",
       " 'G4',\n",
       " 'G#4',\n",
       " 'G#4',\n",
       " 'G4',\n",
       " 'G4',\n",
       " 'F4',\n",
       " 'F4',\n",
       " 'E-4',\n",
       " 'E-4',\n",
       " 'C#4',\n",
       " 'C#4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'D4',\n",
       " 'D4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'F4',\n",
       " 'F4',\n",
       " 'G3',\n",
       " 'C5',\n",
       " 'C6',\n",
       " 'G3',\n",
       " 'G#3',\n",
       " 'C6',\n",
       " 'C5',\n",
       " 'G#3',\n",
       " 'G3',\n",
       " 'C5',\n",
       " 'E4',\n",
       " 'C4',\n",
       " 'F4',\n",
       " 'C4',\n",
       " 'F4',\n",
       " 'C5',\n",
       " 'E4',\n",
       " 'C5',\n",
       " 'G4',\n",
       " 'C6',\n",
       " 'G#4',\n",
       " 'C5',\n",
       " 'G#4',\n",
       " 'C6',\n",
       " 'G4',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C#5',\n",
       " 'B-4',\n",
       " 'F#5',\n",
       " 'F#4',\n",
       " 'B4',\n",
       " 'F4',\n",
       " 'C#5',\n",
       " 'E4',\n",
       " 'C5',\n",
       " 'C5',\n",
       " '4.10',\n",
       " 'F5',\n",
       " 'C#4',\n",
       " 'E5',\n",
       " 'E5',\n",
       " '1.4',\n",
       " 'C#6',\n",
       " 'C6',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'G4',\n",
       " 'B-5',\n",
       " 'C4',\n",
       " 'G#5',\n",
       " 'C4',\n",
       " 'F5',\n",
       " 'G#3',\n",
       " 'C#5',\n",
       " 'B-3',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'C#6',\n",
       " 'F4',\n",
       " 'C6',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'G4',\n",
       " 'B-5',\n",
       " 'C4',\n",
       " 'G#5',\n",
       " 'F4',\n",
       " 'F4',\n",
       " 'F5',\n",
       " 'G4',\n",
       " 'G#4',\n",
       " 'B4',\n",
       " 'B3',\n",
       " 'F4',\n",
       " 'C5',\n",
       " 'E4',\n",
       " 'C5',\n",
       " 'C5',\n",
       " 'F4',\n",
       " 'F4',\n",
       " 'G4',\n",
       " 'G4',\n",
       " 'G#4',\n",
       " 'G#4',\n",
       " 'G4',\n",
       " 'G4',\n",
       " 'F4',\n",
       " 'F4',\n",
       " 'E-4',\n",
       " 'E-4',\n",
       " 'C#4',\n",
       " 'C#4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'D4',\n",
       " 'D4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'F4',\n",
       " 'F4',\n",
       " 'G4',\n",
       " 'G4',\n",
       " 'G#4',\n",
       " 'G#4',\n",
       " 'G4',\n",
       " 'G4',\n",
       " 'F4',\n",
       " 'F4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'G#4',\n",
       " 'G#4',\n",
       " 'B-4',\n",
       " 'B-4',\n",
       " 'G#4',\n",
       " 'G#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'G4',\n",
       " 'G4',\n",
       " 'G#4',\n",
       " 'G#4',\n",
       " 'B-4',\n",
       " 'B-4',\n",
       " 'C5',\n",
       " 'C5',\n",
       " 'C#5',\n",
       " 'C#5',\n",
       " 'E-5',\n",
       " 'E-5',\n",
       " 'C#5',\n",
       " 'C#5',\n",
       " 'C5',\n",
       " 'C5',\n",
       " 'B-4',\n",
       " 'B-4',\n",
       " 'C5',\n",
       " 'C5',\n",
       " 'B-4',\n",
       " 'B-4',\n",
       " 'G#4',\n",
       " 'G#4',\n",
       " 'G4',\n",
       " 'G4',\n",
       " 'F4',\n",
       " 'F4',\n",
       " 'E-4',\n",
       " 'E-4',\n",
       " 'C#4',\n",
       " 'C#4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'G#4',\n",
       " 'G#5',\n",
       " 'C4',\n",
       " 'F#5',\n",
       " 'C#4',\n",
       " 'E-4',\n",
       " 'F5',\n",
       " 'F4',\n",
       " 'C#5',\n",
       " 'F#4',\n",
       " 'C5',\n",
       " 'G#4',\n",
       " 'B-4',\n",
       " 'B-4',\n",
       " 'E-4',\n",
       " 'G#4',\n",
       " 'G4',\n",
       " 'G#4',\n",
       " 'E-4',\n",
       " 'G#4',\n",
       " 'F4',\n",
       " 'G#3',\n",
       " 'F4',\n",
       " 'G#3',\n",
       " 'G#5',\n",
       " 'F#4',\n",
       " 'G#3',\n",
       " 'F#4',\n",
       " 'G#3',\n",
       " 'G#5',\n",
       " 'F4',\n",
       " 'G#3',\n",
       " 'C#4',\n",
       " 'F6',\n",
       " 'G#3',\n",
       " 'F6',\n",
       " 'C4',\n",
       " 'E-6',\n",
       " 'G#3',\n",
       " 'C#6',\n",
       " 'C4',\n",
       " 'C6',\n",
       " 'G#3',\n",
       " 'C#6',\n",
       " 'C#4',\n",
       " 'G#5',\n",
       " 'F4',\n",
       " 'F#4',\n",
       " 'G#4',\n",
       " 'C5',\n",
       " 'C#5',\n",
       " 'E-5',\n",
       " 'D5',\n",
       " 'E-5',\n",
       " 'C#5',\n",
       " 'G#5',\n",
       " 'C5',\n",
       " 'B-4',\n",
       " 'G#5',\n",
       " 'G#4',\n",
       " 'F4',\n",
       " 'F4',\n",
       " 'C#6',\n",
       " 'F6',\n",
       " 'C#4',\n",
       " 'G#6',\n",
       " 'B-3',\n",
       " 'G#6',\n",
       " 'B-4',\n",
       " 'F#6',\n",
       " 'F6',\n",
       " 'F6',\n",
       " 'E-6',\n",
       " 'C#6',\n",
       " 'C#6',\n",
       " 'B-3',\n",
       " 'C6',\n",
       " 'B-5',\n",
       " 'B-5',\n",
       " 'C4',\n",
       " 'G#5',\n",
       " 'G5',\n",
       " 'B-5',\n",
       " 'C5',\n",
       " 'G#5',\n",
       " 'F#5',\n",
       " 'F#5',\n",
       " 'F5',\n",
       " 'E5',\n",
       " 'F#5',\n",
       " 'C4',\n",
       " 'F5',\n",
       " 'E-5',\n",
       " 'E-5',\n",
       " 'C#5',\n",
       " 'C5',\n",
       " 'C#5',\n",
       " 'C#4',\n",
       " 'C5',\n",
       " 'E-4',\n",
       " 'B-4',\n",
       " 'F4',\n",
       " 'C5',\n",
       " 'B-4',\n",
       " 'G#4',\n",
       " 'B-4',\n",
       " 'C#4',\n",
       " 'G#4',\n",
       " 'E-4',\n",
       " 'G4',\n",
       " 'F4',\n",
       " 'B-4',\n",
       " 'E-4',\n",
       " 'G#4',\n",
       " 'G4',\n",
       " 'F#4',\n",
       " '3',\n",
       " 'G#3',\n",
       " 'G#4',\n",
       " 'F#4',\n",
       " 'G#3',\n",
       " 'G#4',\n",
       " 'F#4',\n",
       " 'F5',\n",
       " 'G#3',\n",
       " 'F#5',\n",
       " 'G#4',\n",
       " 'F5',\n",
       " 'F#4',\n",
       " 'E-5',\n",
       " 'G#3',\n",
       " 'G#4',\n",
       " 'F#4',\n",
       " 'G#3',\n",
       " 'G#4',\n",
       " 'F#4',\n",
       " 'G#3',\n",
       " 'G#4',\n",
       " 'F#4',\n",
       " 'G#3',\n",
       " 'G#4',\n",
       " 'G4',\n",
       " 'E-4',\n",
       " 'G#4',\n",
       " 'F#4',\n",
       " 'G#3',\n",
       " 'F#4',\n",
       " '3',\n",
       " 'G#3',\n",
       " 'G#4',\n",
       " 'F#4',\n",
       " 'G#3',\n",
       " 'G#4',\n",
       " 'F#4',\n",
       " 'F5',\n",
       " 'G#3',\n",
       " 'F#5',\n",
       " 'G#4',\n",
       " 'F5',\n",
       " 'F#4',\n",
       " 'E-5',\n",
       " 'G#3',\n",
       " 'G#4',\n",
       " 'F#4',\n",
       " 'G#3',\n",
       " 'G#4',\n",
       " 'F#4',\n",
       " 'G#3',\n",
       " 'G#4',\n",
       " 'G#3',\n",
       " 'G#5',\n",
       " 'G#4',\n",
       " 'G#3',\n",
       " 'G#3',\n",
       " 'G#4',\n",
       " 'A3',\n",
       " 'A3',\n",
       " 'B3',\n",
       " 'B3',\n",
       " 'C#4',\n",
       " 'C#4',\n",
       " 'D4',\n",
       " 'D4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'G#4',\n",
       " 'G#4',\n",
       " 'A4',\n",
       " 'A4',\n",
       " 'B4',\n",
       " 'B4',\n",
       " 'C#5',\n",
       " 'C#5',\n",
       " 'D5',\n",
       " 'D5',\n",
       " 'E5',\n",
       " 'E4',\n",
       " 'F#5',\n",
       " 'F#4',\n",
       " 'G#5',\n",
       " 'G#4',\n",
       " 'A5',\n",
       " 'A4',\n",
       " 'D6',\n",
       " 'D5',\n",
       " 'D6',\n",
       " 'D5',\n",
       " 'E-6',\n",
       " 'E-5',\n",
       " 'B-5',\n",
       " 'B-4',\n",
       " 'B-5',\n",
       " 'B-4',\n",
       " 'A5',\n",
       " 'A4',\n",
       " 'G#5',\n",
       " 'G#4',\n",
       " 'B-5',\n",
       " 'B-4',\n",
       " 'A5',\n",
       " 'A4',\n",
       " 'G#5',\n",
       " 'G#4',\n",
       " 'C4',\n",
       " 'G#5',\n",
       " 'C#4',\n",
       " 'E-4',\n",
       " 'F4',\n",
       " 'E-4',\n",
       " 'C#4',\n",
       " 'E-4',\n",
       " 'F4',\n",
       " 'E-4',\n",
       " 'C#4',\n",
       " 'E-4',\n",
       " 'F4',\n",
       " 'E-4',\n",
       " 'C#4',\n",
       " 'E-4',\n",
       " 'F4',\n",
       " 'E-4',\n",
       " 'G#5',\n",
       " 'C4',\n",
       " 'F#5',\n",
       " 'E-5',\n",
       " 'C5',\n",
       " 'E-4',\n",
       " 'G#5',\n",
       " 'C4',\n",
       " 'G#5',\n",
       " 'C#4',\n",
       " 'E-4',\n",
       " 'F4',\n",
       " 'E-4',\n",
       " 'C#4',\n",
       " 'E-4',\n",
       " 'F4',\n",
       " 'E-4',\n",
       " 'C#4',\n",
       " 'E-4',\n",
       " 'G#5',\n",
       " 'F4',\n",
       " 'E-4',\n",
       " 'B-5',\n",
       " 'C#4',\n",
       " 'E-4',\n",
       " 'G#5',\n",
       " 'F4',\n",
       " 'E-4',\n",
       " 'G#5',\n",
       " 'C4',\n",
       " 'F#5',\n",
       " 'E-5',\n",
       " 'C5',\n",
       " 'E-4',\n",
       " 'G#5',\n",
       " 'C4',\n",
       " 'G#5',\n",
       " 'C#4',\n",
       " 'G#4',\n",
       " 'G#3',\n",
       " 'G#4',\n",
       " 'C#4',\n",
       " 'C#5',\n",
       " 'C#4',\n",
       " 'C#5',\n",
       " 'C#4',\n",
       " 'C#5',\n",
       " 'C#4',\n",
       " 'C#5',\n",
       " 'C#4',\n",
       " 'C#5',\n",
       " 'C#4',\n",
       " 'C#5',\n",
       " 'C#4',\n",
       " 'D5',\n",
       " 'D4',\n",
       " 'E5',\n",
       " 'E4',\n",
       " 'F#5',\n",
       " 'F#4',\n",
       " 'G5',\n",
       " 'G4',\n",
       " 'A5',\n",
       " 'A4',\n",
       " 'B5',\n",
       " 'B4',\n",
       " 'C#6',\n",
       " 'C#5',\n",
       " 'D6',\n",
       " 'D5',\n",
       " 'D6',\n",
       " 'D5',\n",
       " 'E-6',\n",
       " 'E-5',\n",
       " 'B-5',\n",
       " 'B-4',\n",
       " 'B-5',\n",
       " 'B-4',\n",
       " 'A5',\n",
       " 'A4',\n",
       " 'G#5',\n",
       " 'G#4',\n",
       " 'B-5',\n",
       " 'B-4',\n",
       " 'A5',\n",
       " 'A4',\n",
       " 'G#5',\n",
       " 'G#4',\n",
       " 'C4',\n",
       " 'G#5',\n",
       " 'C#4',\n",
       " 'E-4',\n",
       " 'F4',\n",
       " 'E-4',\n",
       " 'C#4',\n",
       " 'E-4',\n",
       " 'F4',\n",
       " 'E-4',\n",
       " 'C#4',\n",
       " 'E-4',\n",
       " 'F4',\n",
       " 'E-4',\n",
       " 'C#4',\n",
       " 'E-4',\n",
       " 'F4',\n",
       " 'E-4',\n",
       " 'G#5',\n",
       " 'C4',\n",
       " 'F#5',\n",
       " 'E-5',\n",
       " 'C5',\n",
       " 'E-4',\n",
       " 'G#5',\n",
       " 'C4',\n",
       " 'G#5',\n",
       " 'C#4',\n",
       " 'E-4',\n",
       " 'F4',\n",
       " 'E-4',\n",
       " 'C#4',\n",
       " 'E-4',\n",
       " 'G#4',\n",
       " 'F4',\n",
       " 'E-4',\n",
       " 'C#4',\n",
       " 'E-4',\n",
       " 'G#4',\n",
       " 'F4',\n",
       " 'E-4',\n",
       " 'B-4',\n",
       " 'C#4',\n",
       " 'E-4',\n",
       " 'G#4',\n",
       " 'F4',\n",
       " 'E-4',\n",
       " 'G#4',\n",
       " 'C4',\n",
       " 'F#4',\n",
       " 'E-4',\n",
       " 'C4',\n",
       " 'E-4',\n",
       " 'G#3',\n",
       " 'C4',\n",
       " 'C#4',\n",
       " 'G#3',\n",
       " 'E-4',\n",
       " 'C4',\n",
       " 'F4',\n",
       " 'C#4',\n",
       " 'C5',\n",
       " 'E-4',\n",
       " 'F4',\n",
       " '0.5',\n",
       " '5.9',\n",
       " 'F5',\n",
       " 'F4',\n",
       " 'G4',\n",
       " 'A4',\n",
       " 'G4',\n",
       " 'A5',\n",
       " 'F4',\n",
       " 'C6',\n",
       " 'F4',\n",
       " 'G4',\n",
       " 'A4',\n",
       " 'G4',\n",
       " 'F6',\n",
       " 'F4',\n",
       " 'F#6',\n",
       " 'E-5',\n",
       " '6.9',\n",
       " 'E-5',\n",
       " 'F5',\n",
       " 'E-5',\n",
       " 'C#5',\n",
       " 'F#5',\n",
       " 'C5',\n",
       " 'C#5',\n",
       " 'E-5',\n",
       " 'C#5',\n",
       " 'C6',\n",
       " 'C5',\n",
       " 'E-6',\n",
       " 'C5',\n",
       " 'C#5',\n",
       " 'E-5',\n",
       " 'C#5',\n",
       " 'F#6',\n",
       " 'C5',\n",
       " '7',\n",
       " '4.10',\n",
       " 'G5',\n",
       " 'G4',\n",
       " 'G#4',\n",
       " 'B-4',\n",
       " 'G#4',\n",
       " 'B-5',\n",
       " 'G4',\n",
       " 'E6',\n",
       " 'B-3',\n",
       " 'C4',\n",
       " 'C#4',\n",
       " 'C4',\n",
       " 'G6',\n",
       " 'B-3',\n",
       " 'C4',\n",
       " 'B-3',\n",
       " 'G#3',\n",
       " 'G3',\n",
       " 'G6',\n",
       " 'G5',\n",
       " 'G4',\n",
       " 'G4',\n",
       " 'G5',\n",
       " 'G4',\n",
       " 'G4',\n",
       " 'G#4',\n",
       " 'F5',\n",
       " 'F4',\n",
       " 'G#4',\n",
       " 'B-4',\n",
       " 'E5',\n",
       " 'E4',\n",
       " 'B-4',\n",
       " 'B-4',\n",
       " 'C#6',\n",
       " 'C#5',\n",
       " 'B-4',\n",
       " 'B-4',\n",
       " 'C#5',\n",
       " 'C#4',\n",
       " 'B-4',\n",
       " 'C5',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C#5',\n",
       " 'B-4',\n",
       " 'B-3',\n",
       " 'C#5',\n",
       " 'D5',\n",
       " 'G#4',\n",
       " 'G#3',\n",
       " 'D5',\n",
       " 'E-5',\n",
       " 'F5',\n",
       " 'G#4',\n",
       " 'E-5',\n",
       " 'G#3',\n",
       " 'D5',\n",
       " '2',\n",
       " 'G#4',\n",
       " 'G#3',\n",
       " 'D5',\n",
       " 'E-5',\n",
       " 'F5',\n",
       " 'G#4',\n",
       " 'E-5',\n",
       " 'G#3',\n",
       " 'D5',\n",
       " 'G#4',\n",
       " 'G#3',\n",
       " 'G#4',\n",
       " 'G#3',\n",
       " 'G#4',\n",
       " 'G#3',\n",
       " 'G#4',\n",
       " 'G#3',\n",
       " 'G#4',\n",
       " 'G#3',\n",
       " 'G#4',\n",
       " 'G#3',\n",
       " 'G#4',\n",
       " 'G#3',\n",
       " 'G#4',\n",
       " 'G#3',\n",
       " 'B4',\n",
       " '7.11',\n",
       " 'B3',\n",
       " 'B4',\n",
       " 'B3',\n",
       " 'B4',\n",
       " 'B3',\n",
       " 'B4',\n",
       " 'B3',\n",
       " 'B4',\n",
       " 'B3',\n",
       " 'B4',\n",
       " 'B3',\n",
       " 'B4',\n",
       " 'B3',\n",
       " 'B4',\n",
       " 'B3',\n",
       " 'B-5',\n",
       " '7.10',\n",
       " 'B-4',\n",
       " 'B-5',\n",
       " 'B-4',\n",
       " 'B-5',\n",
       " 'B-4',\n",
       " 'B-5',\n",
       " 'B-4',\n",
       " 'B-5',\n",
       " 'B-4',\n",
       " 'B-5',\n",
       " 'B-4',\n",
       " 'B-5',\n",
       " 'B-4',\n",
       " 'B-5',\n",
       " 'B-4',\n",
       " 'C#6',\n",
       " 'C#5',\n",
       " 'G5',\n",
       " 'G#5',\n",
       " 'B-5',\n",
       " 'C#5',\n",
       " 'G#5',\n",
       " 'C#4',\n",
       " 'G5',\n",
       " 'C6',\n",
       " 'C5',\n",
       " 'F5',\n",
       " 'G5',\n",
       " 'G#5',\n",
       " 'C5',\n",
       " 'G5',\n",
       " 'C4',\n",
       " 'F5',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C6',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C#5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'D5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'E5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C6',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C#5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'D5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " '0.4',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C6',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'B-5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'F4',\n",
       " 'F4',\n",
       " 'G4',\n",
       " 'G4',\n",
       " 'G#4',\n",
       " 'G#4',\n",
       " 'G4',\n",
       " 'G4',\n",
       " 'F4',\n",
       " 'F4',\n",
       " 'E-4',\n",
       " 'E-4',\n",
       " 'C#4',\n",
       " 'C#4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'D4',\n",
       " 'D4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'F4',\n",
       " 'F4',\n",
       " 'F4',\n",
       " 'F4',\n",
       " 'G4',\n",
       " 'G4',\n",
       " 'G#4',\n",
       " 'G#4',\n",
       " 'G4',\n",
       " 'G4',\n",
       " 'F4',\n",
       " 'F4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'G#4',\n",
       " 'G#4',\n",
       " 'B-4',\n",
       " 'B-4',\n",
       " 'G#4',\n",
       " 'G#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'G4',\n",
       " 'G4',\n",
       " 'G#4',\n",
       " 'G#4',\n",
       " 'B-4',\n",
       " 'B-4',\n",
       " 'C5',\n",
       " 'C5',\n",
       " 'C#5',\n",
       " 'C#5',\n",
       " 'E-5',\n",
       " 'E-5',\n",
       " 'C#5',\n",
       " 'C#5',\n",
       " 'C5',\n",
       " 'C5',\n",
       " 'B-4',\n",
       " 'B-4',\n",
       " 'C5',\n",
       " 'C5',\n",
       " 'B-4',\n",
       " 'B-4',\n",
       " 'G#4',\n",
       " 'G#4',\n",
       " 'G4',\n",
       " 'G4',\n",
       " 'F4',\n",
       " 'F4',\n",
       " 'E-4',\n",
       " 'E-4',\n",
       " 'C#4',\n",
       " 'C#4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'G#4',\n",
       " 'G#5',\n",
       " 'C4',\n",
       " 'F#5',\n",
       " 'C#4',\n",
       " 'E-4',\n",
       " 'F5',\n",
       " 'F4',\n",
       " 'C#5',\n",
       " 'F#4',\n",
       " 'C5',\n",
       " 'G#4',\n",
       " 'B-4',\n",
       " 'B-4',\n",
       " 'E-4',\n",
       " 'G#4',\n",
       " 'G4',\n",
       " 'G#4',\n",
       " 'E-4',\n",
       " 'G#4',\n",
       " 'F4',\n",
       " 'G#3',\n",
       " 'F4',\n",
       " 'G#3',\n",
       " 'G#5',\n",
       " 'F#4',\n",
       " 'G#3',\n",
       " 'F#4',\n",
       " 'G#3',\n",
       " 'G#5',\n",
       " 'F4',\n",
       " 'G#3',\n",
       " 'C#4',\n",
       " 'F6',\n",
       " 'G#3',\n",
       " 'F6',\n",
       " 'F4',\n",
       " 'E-6',\n",
       " 'A3',\n",
       " 'C#6',\n",
       " 'B-3',\n",
       " 'C6',\n",
       " 'B-4',\n",
       " 'G4',\n",
       " 'C6',\n",
       " '5.9',\n",
       " 'A4',\n",
       " 'B-4',\n",
       " 'C5',\n",
       " 'E5',\n",
       " 'F5',\n",
       " 'G5',\n",
       " 'F#5',\n",
       " 'G5',\n",
       " 'F5',\n",
       " 'C6',\n",
       " 'E5',\n",
       " 'D5',\n",
       " 'C6',\n",
       " 'C5',\n",
       " '5.9',\n",
       " 'A6',\n",
       " 'A6',\n",
       " '4.7',\n",
       " 'G6',\n",
       " 'F6',\n",
       " 'E6',\n",
       " 'F6',\n",
       " 'A3',\n",
       " 'F4',\n",
       " 'C6',\n",
       " 'A4',\n",
       " 'B-4',\n",
       " 'C5',\n",
       " 'C6',\n",
       " 'E5',\n",
       " 'F5',\n",
       " 'C6',\n",
       " 'G5',\n",
       " 'D6',\n",
       " 'C6',\n",
       " 'D6',\n",
       " 'C6',\n",
       " 'D6',\n",
       " ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377931af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
