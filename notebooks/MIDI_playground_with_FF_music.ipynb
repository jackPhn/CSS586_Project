{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3518b31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pathlib\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sys\n",
    "from music21 import converter, instrument, note, chord\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, BatchNormalization, Dropout, Dense, Activation\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from musiclearn import config\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c999885",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36db28d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_dir = pathlib.Path(config.FF_MIDI_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748c5918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes(midi_dir):\n",
    "    \"\"\" Get all the notes and chords from the midi files in the collection /ff_midi_songs \"\"\"\n",
    "    notes = []\n",
    "    \n",
    "    files_dir = str(midi_dir) + \"/*.mid\"\n",
    "    for file in glob.glob(files_dir):\n",
    "        midi = converter.parse(file)\n",
    "        \n",
    "        print(\"Parsing %s\" % file)\n",
    "        \n",
    "        notes_to_parse = None\n",
    "        \n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse()\n",
    "        except: # file has notes in a flat structure\n",
    "            notes_to_parse = midi.flat.notes\n",
    "            \n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                 notes.append(str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "    \n",
    "    \"\"\"\n",
    "    notes_file = midi_dir + \"/notes\"\n",
    "    with open(notes_file, 'wb') as fp:\n",
    "        pickle.dump(notes, fp) \"\"\"\n",
    "    \n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dee71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the neural network \"\"\"\n",
    "    sequence_length  = 100\n",
    "    \n",
    "    # get all pitch name\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    \n",
    "    # create a dictionary to map pitches to integers\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "    \n",
    "    network_input = []\n",
    "    network_output = []\n",
    "    \n",
    "    # create input sequences and teh corresponding outputs\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i : i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "        \n",
    "    n_samples = len(network_input)\n",
    "    \n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    network_input = np.reshape(network_input, (n_samples, sequence_length, 1))\n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "    \n",
    "    network_output = keras.utils.to_categorical(network_output)\n",
    "    \n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a85d488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(network_input, n_vocab):\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        LSTM(\n",
    "            512,\n",
    "            input_shape=(network_input.shape[1], network_input.shape[2]),\n",
    "            recurrent_dropout=0.3,\n",
    "            return_sequences=True\n",
    "        ),\n",
    "        LSTM(512, return_sequences=True, recurrent_dropout=0.3),\n",
    "        LSTM(512),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(256),\n",
    "        Activation('relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(n_vocab),\n",
    "        Activation('softmax')\n",
    "    ])\"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
    "        recurrent_dropout=0.3,\n",
    "        return_sequences=True\n",
    "    ))\n",
    "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
    "    model.add(LSTM(512))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd9e12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(notes, epochs = 200, batch_size = 128):\n",
    "    \"\"\" Train a neural network to generate music \"\"\"\n",
    "    # get amount of pitch names\n",
    "    n_vocab = len(set(notes))\n",
    "    \n",
    "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
    "\n",
    "    model = lstm_model(network_input, n_vocab)\n",
    "    \n",
    "    # train the network\n",
    "    filepath = \"saved_weight.hdf5\"\n",
    "    \n",
    "    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath,\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        node='min'\n",
    "    )\n",
    "    \n",
    "    callback_list = [checkpoint_cb]\n",
    "    \n",
    "    model.fit(network_input, network_output, epochs=epochs, batch_size=batch_size, callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf8b0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features\n",
    "notes = get_notes(midi_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798c4140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "train_network(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323fe3d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c264cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
