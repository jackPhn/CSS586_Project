{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9a1d1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pathlib\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from music21 import *\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, BatchNormalization, Dropout, Dense, Activation\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from musiclearn import config\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d564339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_midi(file):\n",
    "    \"\"\" Read a midi file and extract piano track \"\"\"\n",
    "    print(\"Loading misic file:\", file)\n",
    "    \n",
    "    notes = []\n",
    "    \n",
    "    notes_to_parse = None\n",
    "    \n",
    "    # parsing a midi file\n",
    "    midi = converter.parse(file)\n",
    "    \n",
    "    # grouping based on different instruments\n",
    "    s2 = instrument.partitionByInstrument(midi)\n",
    "    \n",
    "    # Looping over all the instruments\n",
    "    for part in s2.parts:\n",
    "        # select elements of only piano\n",
    "        if \"Piano\" in str(part):\n",
    "            notes_to_parse = part.recurse()\n",
    "    \n",
    "    # if there are notes to parse\n",
    "    if notes_to_parse is not None:\n",
    "        # finding whether an element is a note or a chord\n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):   # is note\n",
    "                notes.append(str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord): # is chord\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "    \n",
    "    return np.array(notes)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "137dbf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the part to Schubert\n",
    "midi_path = pathlib.Path(config.MUSICNET_MIDI_DIR)\n",
    "schubert_path = midi_path / \"Schubert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48a9b218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1734_sy_sps93.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1727_schubert_op114_2.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1752_sy_sps14.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1756_sy_sps53.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1757_d958-1.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1751_sy_sps13.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1763_scbt1421.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1764_scbt1422.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1777_sy_sps23.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1730_schubert_op114_5.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1759_d958-3.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1758_d958-2.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1772_sy_sps42.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1733_sy_sps92.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1742_sb163m2.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1728_schubert_op114_3.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1750_sy_sps12.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1768_sy_sps32.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1765_scbt1423.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1775_sy_sps21.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1771_sy_sps41.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1735_sy_sps94.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1729_schubert_op114_4.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1755_sy_sps52.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1760_d958-4.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1749_sy_sps11.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1766_scbt1424.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1773_sy_sps43.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1739_sb99m4.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1776_sy_sps22.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-e905dfa11e8a>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  notes_array = np.array([read_midi(str(schubert_path/fname)) for fname in files_names])\n"
     ]
    }
   ],
   "source": [
    "# read the files\n",
    "files_names = [i for i in os.listdir(schubert_path) if i.endswith(\".mid\")]\n",
    "\n",
    "# extract the notes from piano tracks\n",
    "notes_array = np.array([read_midi(str(schubert_path/fname)) for fname in files_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36b6f217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. unique notes = 312\n"
     ]
    }
   ],
   "source": [
    "# convert 2D array to 1D\n",
    "notes_ = [element for note_ in notes_array for element in note_]\n",
    "\n",
    "# number of unique notes\n",
    "unique_notes = list(set(notes_))\n",
    "print(\"No. unique notes =\", len(unique_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89411eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([208.,  38.,  18.,  11.,   7.,   8.,  11.,   8.,   1.,   2.]),\n",
       " array([1.0000e+00, 1.9010e+02, 3.7920e+02, 5.6830e+02, 7.5740e+02,\n",
       "        9.4650e+02, 1.1356e+03, 1.3247e+03, 1.5138e+03, 1.7029e+03,\n",
       "        1.8920e+03]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 302,
       "width": 319
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# computing frequency of each note\n",
    "freq = dict(Counter(notes_))\n",
    "\n",
    "# consider only the frequencies\n",
    "no = [count for _, count in freq.items()]\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist(no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b307af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n"
     ]
    }
   ],
   "source": [
    "# filter out the notes that have a frequency lower than 50\n",
    "frequent_notes = [note_ for note_, count in freq.items() if count >= 50]\n",
    "print(len(frequent_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87619f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-0260187a6469>:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  new_music = np.array(new_music)\n"
     ]
    }
   ],
   "source": [
    "# filter out the notes with low frequency from the original data\n",
    "new_music = []\n",
    "\n",
    "for notes in notes_array:\n",
    "    temp = []\n",
    "    for note_ in notes:\n",
    "        if note_ in frequent_notes:\n",
    "            temp.append(note_)\n",
    "    new_music.append(temp)\n",
    "    \n",
    "new_music = np.array(new_music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d808ed3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for training\n",
    "# number of time steps\n",
    "no_timesteps = 32\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for note_ in new_music:\n",
    "    for i in range(0, len(note_) - no_timesteps, 1):\n",
    "        # preparing the input and outout sequence\n",
    "        input_ = note_[i: i + no_timesteps]\n",
    "        output_ = note_[i + no_timesteps]\n",
    "        \n",
    "        X.append(input_)\n",
    "        Y.append(output_)\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "557d65a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign unique integer to every note\n",
    "unique_X = list(set(X.ravel()))\n",
    "X_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_X))\n",
    "\n",
    "unique_Y = list(set(Y))\n",
    "Y_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0d133de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the input sequence\n",
    "X_seq = []\n",
    "for i in X:\n",
    "    temp = []\n",
    "    for j in i:\n",
    "        # convert notes to unique integers\n",
    "        temp.append(X_note_to_int[j])\n",
    "    X_seq.append(temp)\n",
    "\n",
    "X_seq = np.array(X_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34323d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the output note\n",
    "Y_seq = np.array([Y_note_to_int[i] for i in Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad0c2dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split 80/20\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_seq, Y_seq, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16778872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm():\n",
    "    \"\"\" LSTM model \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128,return_sequences=True))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6447a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 32, 100)           17600     \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 32, 64)            19264     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 16, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16, 128)           24704     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 8, 256)            98560     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 176)               45232     \n",
      "=================================================================\n",
      "Total params: 271,152\n",
      "Trainable params: 271,152\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# embedding layber\n",
    "model.add(Embedding(len(unique_X), 100, input_length = no_timesteps, trainable=True))\n",
    "\n",
    "model.add(Conv1D(64,3, padding='causal',activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "    \n",
    "model.add(Conv1D(128,3,activation='relu',dilation_rate=2,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "\n",
    "model.add(Conv1D(256,3,activation='relu',dilation_rate=4,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "          \n",
    "#model.add(Conv1D(256,5,activation='relu'))    \n",
    "model.add(GlobalMaxPool1D())\n",
    "    \n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(unique_Y), activation='softmax'))\n",
    "    \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "053f9f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "478/478 [==============================] - 8s 13ms/step - loss: 4.5341 - val_loss: 4.0248\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.02480, saving model to wavenet_weights.hdf5\n",
      "Epoch 2/50\n",
      "478/478 [==============================] - 7s 14ms/step - loss: 3.7893 - val_loss: 3.7909\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.02480 to 3.79091, saving model to wavenet_weights.hdf5\n",
      "Epoch 3/50\n",
      "478/478 [==============================] - 7s 14ms/step - loss: 3.5962 - val_loss: 3.6483\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.79091 to 3.64834, saving model to wavenet_weights.hdf5\n",
      "Epoch 4/50\n",
      "478/478 [==============================] - 7s 14ms/step - loss: 3.4756 - val_loss: 3.5964\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.64834 to 3.59640, saving model to wavenet_weights.hdf5\n",
      "Epoch 5/50\n",
      "478/478 [==============================] - 7s 14ms/step - loss: 3.3767 - val_loss: 3.5041\n",
      "\n",
      "Epoch 00005: val_loss improved from 3.59640 to 3.50408, saving model to wavenet_weights.hdf5\n",
      "Epoch 6/50\n",
      "478/478 [==============================] - 7s 14ms/step - loss: 3.2952 - val_loss: 3.4147\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.50408 to 3.41474, saving model to wavenet_weights.hdf5\n",
      "Epoch 7/50\n",
      "478/478 [==============================] - 6s 13ms/step - loss: 3.2311 - val_loss: 3.3949\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.41474 to 3.39492, saving model to wavenet_weights.hdf5\n",
      "Epoch 8/50\n",
      "478/478 [==============================] - 7s 14ms/step - loss: 3.1689 - val_loss: 3.3591\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.39492 to 3.35912, saving model to wavenet_weights.hdf5\n",
      "Epoch 9/50\n",
      "478/478 [==============================] - 7s 14ms/step - loss: 3.1194 - val_loss: 3.3319\n",
      "\n",
      "Epoch 00009: val_loss improved from 3.35912 to 3.33192, saving model to wavenet_weights.hdf5\n",
      "Epoch 10/50\n",
      "478/478 [==============================] - 7s 14ms/step - loss: 3.0692 - val_loss: 3.2892\n",
      "\n",
      "Epoch 00010: val_loss improved from 3.33192 to 3.28916, saving model to wavenet_weights.hdf5\n",
      "Epoch 11/50\n",
      "478/478 [==============================] - 6s 13ms/step - loss: 3.0396 - val_loss: 3.2486\n",
      "\n",
      "Epoch 00011: val_loss improved from 3.28916 to 3.24860, saving model to wavenet_weights.hdf5\n",
      "Epoch 12/50\n",
      "478/478 [==============================] - 6s 13ms/step - loss: 2.9825 - val_loss: 3.2171\n",
      "\n",
      "Epoch 00012: val_loss improved from 3.24860 to 3.21705, saving model to wavenet_weights.hdf5\n",
      "Epoch 13/50\n",
      "478/478 [==============================] - 7s 14ms/step - loss: 2.9521 - val_loss: 3.2135\n",
      "\n",
      "Epoch 00013: val_loss improved from 3.21705 to 3.21351, saving model to wavenet_weights.hdf5\n",
      "Epoch 14/50\n",
      "478/478 [==============================] - 7s 14ms/step - loss: 2.9166 - val_loss: 3.1988\n",
      "\n",
      "Epoch 00014: val_loss improved from 3.21351 to 3.19880, saving model to wavenet_weights.hdf5\n",
      "Epoch 15/50\n",
      "478/478 [==============================] - 6s 13ms/step - loss: 2.8931 - val_loss: 3.1534\n",
      "\n",
      "Epoch 00015: val_loss improved from 3.19880 to 3.15344, saving model to wavenet_weights.hdf5\n",
      "Epoch 16/50\n",
      "478/478 [==============================] - 6s 13ms/step - loss: 2.8583 - val_loss: 3.1426\n",
      "\n",
      "Epoch 00016: val_loss improved from 3.15344 to 3.14255, saving model to wavenet_weights.hdf5\n",
      "Epoch 17/50\n",
      "478/478 [==============================] - 7s 14ms/step - loss: 2.8187 - val_loss: 3.1285\n",
      "\n",
      "Epoch 00017: val_loss improved from 3.14255 to 3.12845, saving model to wavenet_weights.hdf5\n",
      "Epoch 18/50\n",
      "478/478 [==============================] - 7s 14ms/step - loss: 2.8047 - val_loss: 3.1024\n",
      "\n",
      "Epoch 00018: val_loss improved from 3.12845 to 3.10241, saving model to wavenet_weights.hdf5\n",
      "Epoch 19/50\n",
      "478/478 [==============================] - 6s 13ms/step - loss: 2.7600 - val_loss: 3.1206\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 3.10241\n",
      "Epoch 20/50\n",
      "478/478 [==============================] - 6s 13ms/step - loss: 2.7530 - val_loss: 3.0762\n",
      "\n",
      "Epoch 00020: val_loss improved from 3.10241 to 3.07617, saving model to wavenet_weights.hdf5\n",
      "Epoch 21/50\n",
      "478/478 [==============================] - 6s 14ms/step - loss: 2.7451 - val_loss: 3.0640\n",
      "\n",
      "Epoch 00021: val_loss improved from 3.07617 to 3.06404, saving model to wavenet_weights.hdf5\n",
      "Epoch 22/50\n",
      "478/478 [==============================] - 7s 14ms/step - loss: 2.7287 - val_loss: 3.0574\n",
      "\n",
      "Epoch 00022: val_loss improved from 3.06404 to 3.05735, saving model to wavenet_weights.hdf5\n",
      "Epoch 23/50\n",
      "478/478 [==============================] - 7s 14ms/step - loss: 2.6949 - val_loss: 3.0265\n",
      "\n",
      "Epoch 00023: val_loss improved from 3.05735 to 3.02651, saving model to wavenet_weights.hdf5\n",
      "Epoch 24/50\n",
      "478/478 [==============================] - 7s 14ms/step - loss: 2.6764 - val_loss: 3.0262\n",
      "\n",
      "Epoch 00024: val_loss improved from 3.02651 to 3.02619, saving model to wavenet_weights.hdf5\n",
      "Epoch 25/50\n",
      "478/478 [==============================] - 6s 14ms/step - loss: 2.6705 - val_loss: 3.0091\n",
      "\n",
      "Epoch 00025: val_loss improved from 3.02619 to 3.00906, saving model to wavenet_weights.hdf5\n",
      "Epoch 26/50\n",
      "478/478 [==============================] - 6s 13ms/step - loss: 2.6501 - val_loss: 3.0168\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 3.00906\n",
      "Epoch 27/50\n",
      "478/478 [==============================] - 7s 14ms/step - loss: 2.6405 - val_loss: 2.9913\n",
      "\n",
      "Epoch 00027: val_loss improved from 3.00906 to 2.99133, saving model to wavenet_weights.hdf5\n",
      "Epoch 28/50\n",
      "478/478 [==============================] - 6s 13ms/step - loss: 2.6238 - val_loss: 2.9932\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.99133\n",
      "Epoch 29/50\n",
      "478/478 [==============================] - 7s 15ms/step - loss: 2.6079 - val_loss: 2.9871\n",
      "\n",
      "Epoch 00029: val_loss improved from 2.99133 to 2.98714, saving model to wavenet_weights.hdf5\n",
      "Epoch 30/50\n",
      "478/478 [==============================] - 7s 14ms/step - loss: 2.5890 - val_loss: 2.9618\n",
      "\n",
      "Epoch 00030: val_loss improved from 2.98714 to 2.96180, saving model to wavenet_weights.hdf5\n",
      "Epoch 31/50\n",
      "478/478 [==============================] - 7s 14ms/step - loss: 2.5753 - val_loss: 2.9756\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.96180\n",
      "Epoch 32/50\n",
      "478/478 [==============================] - 7s 14ms/step - loss: 2.5693 - val_loss: 2.9661\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.96180\n",
      "Epoch 33/50\n",
      "478/478 [==============================] - 6s 13ms/step - loss: 2.5618 - val_loss: 2.9600\n",
      "\n",
      "Epoch 00033: val_loss improved from 2.96180 to 2.96001, saving model to wavenet_weights.hdf5\n",
      "Epoch 34/50\n",
      "478/478 [==============================] - 7s 14ms/step - loss: 2.5467 - val_loss: 2.9495\n",
      "\n",
      "Epoch 00034: val_loss improved from 2.96001 to 2.94946, saving model to wavenet_weights.hdf5\n",
      "Epoch 35/50\n",
      "478/478 [==============================] - 7s 14ms/step - loss: 2.5449 - val_loss: 2.9414\n",
      "\n",
      "Epoch 00035: val_loss improved from 2.94946 to 2.94140, saving model to wavenet_weights.hdf5\n",
      "Epoch 36/50\n",
      "478/478 [==============================] - 7s 14ms/step - loss: 2.5307 - val_loss: 2.9378\n",
      "\n",
      "Epoch 00036: val_loss improved from 2.94140 to 2.93783, saving model to wavenet_weights.hdf5\n",
      "Epoch 37/50\n",
      "478/478 [==============================] - 6s 13ms/step - loss: 2.5231 - val_loss: 2.9338\n",
      "\n",
      "Epoch 00037: val_loss improved from 2.93783 to 2.93377, saving model to wavenet_weights.hdf5\n",
      "Epoch 38/50\n",
      "478/478 [==============================] - 7s 14ms/step - loss: 2.5182 - val_loss: 2.9290\n",
      "\n",
      "Epoch 00038: val_loss improved from 2.93377 to 2.92903, saving model to wavenet_weights.hdf5\n",
      "Epoch 39/50\n",
      "478/478 [==============================] - 6s 13ms/step - loss: 2.5099 - val_loss: 2.9243\n",
      "\n",
      "Epoch 00039: val_loss improved from 2.92903 to 2.92434, saving model to wavenet_weights.hdf5\n",
      "Epoch 40/50\n",
      "478/478 [==============================] - 7s 14ms/step - loss: 2.5009 - val_loss: 2.9188\n",
      "\n",
      "Epoch 00040: val_loss improved from 2.92434 to 2.91884, saving model to wavenet_weights.hdf5\n",
      "Epoch 41/50\n",
      "478/478 [==============================] - 6s 13ms/step - loss: 2.4800 - val_loss: 2.9102\n",
      "\n",
      "Epoch 00041: val_loss improved from 2.91884 to 2.91020, saving model to wavenet_weights.hdf5\n",
      "Epoch 42/50\n",
      "478/478 [==============================] - 7s 14ms/step - loss: 2.4895 - val_loss: 2.9090\n",
      "\n",
      "Epoch 00042: val_loss improved from 2.91020 to 2.90900, saving model to wavenet_weights.hdf5\n",
      "Epoch 43/50\n",
      "478/478 [==============================] - 7s 14ms/step - loss: 2.4767 - val_loss: 2.8942\n",
      "\n",
      "Epoch 00043: val_loss improved from 2.90900 to 2.89424, saving model to wavenet_weights.hdf5\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478/478 [==============================] - 7s 14ms/step - loss: 2.4541 - val_loss: 2.8933\n",
      "\n",
      "Epoch 00044: val_loss improved from 2.89424 to 2.89326, saving model to wavenet_weights.hdf5\n",
      "Epoch 45/50\n",
      "478/478 [==============================] - 7s 14ms/step - loss: 2.4715 - val_loss: 2.8858\n",
      "\n",
      "Epoch 00045: val_loss improved from 2.89326 to 2.88581, saving model to wavenet_weights.hdf5\n",
      "Epoch 46/50\n",
      "478/478 [==============================] - 7s 14ms/step - loss: 2.4498 - val_loss: 2.8846\n",
      "\n",
      "Epoch 00046: val_loss improved from 2.88581 to 2.88461, saving model to wavenet_weights.hdf5\n",
      "Epoch 47/50\n",
      "478/478 [==============================] - 7s 14ms/step - loss: 2.4578 - val_loss: 2.9061\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2.88461\n",
      "Epoch 48/50\n",
      "478/478 [==============================] - 7s 15ms/step - loss: 2.4485 - val_loss: 2.8717\n",
      "\n",
      "Epoch 00048: val_loss improved from 2.88461 to 2.87170, saving model to wavenet_weights.hdf5\n",
      "Epoch 49/50\n",
      "478/478 [==============================] - 7s 14ms/step - loss: 2.4481 - val_loss: 2.8715\n",
      "\n",
      "Epoch 00049: val_loss improved from 2.87170 to 2.87145, saving model to wavenet_weights.hdf5\n",
      "Epoch 50/50\n",
      "478/478 [==============================] - 7s 14ms/step - loss: 2.4384 - val_loss: 2.8844\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2.87145\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = ModelCheckpoint(\n",
    "    \"wavenet_weights.hdf5\", \n",
    "    monitor='val_loss', \n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    "    )\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    Y_train,\n",
    "                    batch_size=128,\n",
    "                    epochs=50,\n",
    "                    validation_data=(X_val, Y_val),\n",
    "                    verbose=1,\n",
    "                    callbacks=[checkpoint_cb]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a6d5d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trained model\n",
    "model = tf.keras.models.load_model('wavenet_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8704b190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[125, 79, 125, 79, 125, 125, 125, 125, 125, 125]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "ind = np.random.randint(0,len(X_val)-1)\n",
    "\n",
    "random_music = X_val[ind]\n",
    "\n",
    "predictions=[]\n",
    "for i in range(10):\n",
    "\n",
    "    random_music = random_music.reshape(1,no_timesteps)\n",
    "\n",
    "    prob  = model.predict(random_music)[0]\n",
    "    y_pred= np.argmax(prob,axis=0)\n",
    "    predictions.append(y_pred)\n",
    "\n",
    "    random_music = np.insert(random_music[0],len(random_music[0]),y_pred)\n",
    "    random_music = random_music[1:]\n",
    "    \n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c8a972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert prediction to notes\n",
    "X_int_to_note = dict((number, note_) for number, note_ in enumerate(unique_X)) \n",
    "predicted_notes = [X_int_to_note[i] for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7cea8998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_midi(prediction_output):\n",
    "   \n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        \n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                \n",
    "                cn=int(current_note)\n",
    "                new_note = note.Note(cn)\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "                \n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "            \n",
    "        # pattern is a note\n",
    "        else:\n",
    "            \n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 1\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='wavenet_music.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "724963b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_midi(predicted_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6145aa8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
