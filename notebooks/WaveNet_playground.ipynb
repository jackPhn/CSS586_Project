{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9a1d1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pathlib\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from music21 import *\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, BatchNormalization, Dropout, Dense, Activation\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from musiclearn import config\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d564339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_midi(file):\n",
    "    \"\"\" Read a midi file and extract piano track \"\"\"\n",
    "    print(\"Loading misic file:\", file)\n",
    "    \n",
    "    notes = []\n",
    "    \n",
    "    notes_to_parse = None\n",
    "    \n",
    "    # parsing a midi file\n",
    "    midi = converter.parse(file)\n",
    "    \n",
    "    # grouping based on different instruments\n",
    "    s2 = instrument.partitionByInstrument(midi)\n",
    "    \n",
    "    # Looping over all the instruments\n",
    "    for part in s2.parts:\n",
    "        # select elements of only piano\n",
    "        if \"Piano\" in str(part):\n",
    "            notes_to_parse = part.recurse()\n",
    "    \n",
    "    # if there are notes to parse\n",
    "    if notes_to_parse is not None:\n",
    "        # finding whether an element is a note or a chord\n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):   # is note\n",
    "                notes.append(str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord): # is chord\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "    \n",
    "    return np.array(notes)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "137dbf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the part to Schubert\n",
    "midi_path = pathlib.Path(config.MUSICNET_MIDI_DIR)\n",
    "schubert_path = midi_path / \"Schubert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48a9b218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1734_sy_sps93.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1727_schubert_op114_2.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1752_sy_sps14.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1756_sy_sps53.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1757_d958-1.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1751_sy_sps13.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1763_scbt1421.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1764_scbt1422.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1777_sy_sps23.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1730_schubert_op114_5.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1759_d958-3.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1758_d958-2.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1772_sy_sps42.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1733_sy_sps92.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1742_sb163m2.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1728_schubert_op114_3.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1750_sy_sps12.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1768_sy_sps32.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1765_scbt1423.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1775_sy_sps21.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1771_sy_sps41.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1735_sy_sps94.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1729_schubert_op114_4.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1755_sy_sps52.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1760_d958-4.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1749_sy_sps11.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1766_scbt1424.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1773_sy_sps43.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1739_sb99m4.mid\n",
      "Loading misic file: /csslab-localdata/csslab-si/jack_working_dir/musicnet_midis/Schubert/1776_sy_sps22.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-e905dfa11e8a>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  notes_array = np.array([read_midi(str(schubert_path/fname)) for fname in files_names])\n"
     ]
    }
   ],
   "source": [
    "# read the files\n",
    "files_names = [i for i in os.listdir(schubert_path) if i.endswith(\".mid\")]\n",
    "\n",
    "# extract the notes from piano tracks\n",
    "notes_array = np.array([read_midi(str(schubert_path/fname)) for fname in files_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36b6f217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. unique notes = 312\n"
     ]
    }
   ],
   "source": [
    "# convert 2D array to 1D\n",
    "notes_ = [element for note_ in notes_array for element in note_]\n",
    "\n",
    "# number of unique notes\n",
    "unique_notes = list(set(notes_))\n",
    "print(\"No. unique notes =\", len(unique_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89411eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([208.,  38.,  18.,  11.,   7.,   8.,  11.,   8.,   1.,   2.]),\n",
       " array([1.0000e+00, 1.9010e+02, 3.7920e+02, 5.6830e+02, 7.5740e+02,\n",
       "        9.4650e+02, 1.1356e+03, 1.3247e+03, 1.5138e+03, 1.7029e+03,\n",
       "        1.8920e+03]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn8AAAJdCAYAAABDKhHGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAABYlAAAWJQFJUiTwAAAsVElEQVR4nO3de5QtZX0n7s9XSUCZgOhkoo4zcyDjhfE6YKLiBBBXHI03jBDNRIJJTDS/eMGgo/E2aC7LrBiNQkaNEk9GZoK3CS4immQJBzCYRHHQcYKigaNi8IIoiFwUfH9/VDWn3ezu033O7t7d/T7PWntV77fqrXqrdu3uT791q9ZaAADowx3m3QAAANaP8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEf2mXcDNoqquiLJAUl2zrkpAAC7sy3Jda21g1dbUfjb5YA73elOdz300EPvOu+GAAAs59JLL82NN964R3WFv112HnrooXe9+OKL590OAIBlHX744fnEJz6xc0/qOucPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQkX3m3YDebHvpB+bdhJnZ+drHz7sJAMAq6fkDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjux1+Kuqu1XVs6rqL6rq81V1Y1VdW1Ufqapfqaqpy6iqI6rqnKq6Zqzzqao6qaruuMyynlBVO8b5X19Vf19VJ+7tOgAA9GKfGczj+CRvTnJVkvOSfDHJjyX52SRvT/K4qjq+tdYWKlTVk5O8L8lNSd6V5JokT0zyhiSPHOf5A6rquUlOTfKNJGck+W6S45Jsr6oHttZeNIN1AQDY0mYR/i5L8qQkH2itfX+hsKpeluQfkjw1QxB831h+QJK3Jbk1ydGttY+P5a9Mcm6S46rq6a21MxfNa1uS12UIiQ9tre0cy1+T5GNJTq6q97XWPjqD9QEA2LL2+rBva+3c1trZi4PfWP6VJG8Z3x69aNRxSX40yZkLwW+c/qYkrxjf/vrEYn45yb5JTlsIfmOdbyb5vfHtc/ZuTQAAtr61vuDje+PwlkVlx4zDD02Z/oIkNyQ5oqr2XWGdD05MAwDAEmZx2HeqqtonyS+ObxeHtvuOw8sm67TWbqmqK5LcP8khSS5dQZ2rquo7Se5VVXdurd2wm3ZdvMSo+y1XDwBgK1jLnr/XJnlAknNaa3+1qPzAcXjtEvUWyu+yB3UOXGI8AABZo56/qnp+kpOTfCbJCWuxjD3VWjt8WvnYI3jYOjcHAGBdzbznb7wlyxuT/GOSR7XWrpmYZHe9dAvl39qDOkv1DAIAkBmHv6o6KcO9+D6dIfh9Zcpknx2H95lSf58kB2e4QOTyFda5R5L9k1y5u/P9AAB6N7PwV1UvyXCT5ksyBL+vLTHpuePwsVPGHZnkzkkuaq3dvMI6j5uYBgCAJcwk/I03aH5tkouTPLq1dvUyk783ydVJnl5VD100j/2S/M749s0Tdd6R5OYkzx1v+LxQ56AkLxvfviUAACxrry/4GJ+t+5oMT+y4MMnzq2pysp2tte1J0lq7rqp+NUMI3FFVZ2Z4cseTMtzS5b0ZHvl2m9baFVX14iRvSvLxqnpXdj3e7V5J/tDTPQAAdm8WV/sePA7vmOSkJaY5P8n2hTettbOq6qgkL8/w+Lf9knw+yW8medPi5wAvqnNqVe1M8qIM9w+8Q4aLSl7RWvuzGawHAMCWt9fhr7V2SpJT9qDe3yb5mVXWOTvJ2atdFgAAg7V+vBsAABuI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOjKT8FdVx1XVqVV1YVVdV1Wtqs5YYtrt4/jlXh+eqPPM3Uz/nFmsBwDAVrfPjObziiQPTnJ9kiuT3G+Zac9KsnOJcSckOSTJB5cY//4kl0wp//gK2ggA0L1Zhb8XZgh9n09yVJLzlpqwtXZWhgD4A6rqLkn+a5LvJtm+RPWzWmtLjQMAYDdmEv5aa7eFvara09mckOROSc5srV09i3YBAPCDZtXzNwu/Og7/ZJlpHlJVJyXZL8mXk5zXWrtyrRsGALBVbIjwV1WPSPLAJJct7kWc4gUT72+tqrcnOam1dtMKl3XxEqOWO08RAGBL2Ci3evm1cfi2JcZfkeR5Se6bZP8k90zycxkuHHl2kj9d4/YBAGwJc+/5q6oDMwS5JS/0aK2dn+T8RUU3JHlPVf1dkk8m+fmq+v3W2id3t7zW2uFLtOPiJIetrvUAAJvLRuj5e0aSOyf536u90KO19qUk54xvj5x1wwAAtpqNEP4WLvR46x7W//o43H8GbQEA2NLmGv6q6mEZbg59WWttxx7O5mHj8PKZNAoAYAubd8/fwoUey93eJVX10Clld6iq30ryiCRXJ/nQ7JsHALC1zOSCj6o6Nsmx49u7j8NHVNX28eerW2svmqhzQJKnJbk5yZ/tZhEfq6pPZ7i448tJDkzyyCQPyHDxxy+01q7bu7UAANj6ZnW170OSnDhRdsj4SpIvJHnRxPhfyHCe3kqe6PG6JD+Z5Jgkd03y/SRfTPLHSV7fWnPIFwBgBWb1eLdTkpyyyjpvTvLmFU774tW3CgCASfM+5w8AgHUk/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjswk/FXVcVV1alVdWFXXVVWrqjOWmHbbOH6p15nLLOfEqvqHqrq+qq6tqh1V9YRZrAMAQA/2mdF8XpHkwUmuT3JlkvutoM4nk5w1pfzT0yauqtclOXmc/9uS/HCSpyc5u6qe11o7bfXNBgDoy6zC3wszhLLPJzkqyXkrqHNJa+2Ulcy8qo7IEPz+KclPtNa+OZb/QZKLk7yuqv6ytbZz9U0HAOjHTA77ttbOa619rrXWZjG/KZ4zDn93IfiNy92Z5I+T7Jvkl9Zo2QAAW8Y8L/i4Z1U9u6peNg4ftMy0x4zDD00Z98GJaQAAWMKsDvvuiZ8eX7epqh1JTmytfXFR2f5J/nWS61trV02Zz+fG4X1WstCquniJUSs5TxEAYFObR8/fDUl+O8nhSQ4aXwvnCR6d5MNj4Ftw4Di8don5LZTfZdYNBQDYata956+19rUkr5oovqCqHpPkI0keluRZSd64Rss/fFr52CN42FosEwBgo9gwN3lurd2S5O3j2yMXjVro2Tsw0y2Uf2sNmgUAsKVsmPA3+vo4vO2wb2vtO0m+nORfVNU9ptS59zi8bI3bBgCw6W208PfwcXj5RPm54/CxU+o8bmIaAACWsO7hr6oOq6rbLbeqHp3hZtFJMvlouLeMw5dX1UGL6mxL8htJbk7yjtm3FgBga5nJBR9VdWySY8e3dx+Hj6iq7ePPV7fWXjT+/Pok966qizI8FSRJHpRd9+l7ZWvtosXzb61dVFWvT/KbST5VVe/N8Hi3pyW5a5LneboHAMDuzepq34ckOXGi7JDxlSRfSLIQ/t6Z5ClJfiLDIdsfSvLVJO9Oclpr7cJpC2itnVxV/zdDT9+vJfl+kk8k+YPW2l/OaD0AALa0mYS/8Rm9p6xw2tOTnL6Hy9meZPue1AUAYONd8AEAwBoS/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR2YS/qrquKo6taourKrrqqpV1RlLTHvvqnpJVZ1bVV+qqu9W1Ver6v1V9agl6jxznOdSr+fMYj0AALa6fWY0n1ckeXCS65NcmeR+y0z720meluQfk5yT5Jok903ypCRPqqoXtNbetETd9ye5ZEr5x/es2QAAfZlV+HthhtD3+SRHJTlvmWk/lOT3W2v/Z3FhVR2V5G+S/EFVvae1dtWUume11rbPpskAAP2ZyWHf1tp5rbXPtdbaCqbdPhn8xvLzk+xI8sNJjphFuwAA+EGz6vmble+Nw1uWGP+QqjopyX5JvpzkvNbalevRMACArWDDhL+q+ndJHp3khiQXLDHZCybe31pVb09yUmvtphUu5+IlRi13niIAwJawIW71UlX7JvmfSfZNckpr7ZsTk1yR5HkZLgzZP8k9k/xckp1Jnp3kT9etsQAAm9jce/6q6o5J3pnkkUneleR1k9OM5wOev6johiTvqaq/S/LJJD9fVb/fWvvk7pbXWjt8iXZcnOSw1a8BAMDmMdeevzH4nZHk+CTvTvKMlVw0sqC19qUMt4tJkiNn30IAgK1lbuGvqn4oyZ8neXqS/5Xkv7TWlrrQYzlfH4f7z6ptAABb1VwO+1bVD2fo6Xtykv+R5Jdaa9/fw9k9bBxePou2AQBsZeve8zde3PEXGYLf6VlB8Kuqh04pu0NV/VaSRyS5OsPNowEAWMZMev6q6tgkx45v7z4OH1FV28efr26tvWj8+S1JfiZDYPtykldV1eQsd7TWdix6/7Gq+nSGizu+nOTADBeIPCDDxR+/0Fq7bhbrAgCwlc3qsO9Dkpw4UXbI+EqSLyRZCH8Hj8N/meRVy8xzx6KfX5fkJ5Mck+SuSb6f5ItJ/jjJ61trDvkCAKzATMJfa+2UJKescNqj92D+L15tHQAAbm9D3OQZAID1IfwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHZlJ+Kuq46rq1Kq6sKquq6pWVWfsps4RVXVOVV1TVTdW1aeq6qSquuMydZ5QVTuq6tqqur6q/r6qTpzFOgAA9GCfGc3nFUkenOT6JFcmud9yE1fVk5O8L8lNSd6V5JokT0zyhiSPTHL8lDrPTXJqkm8kOSPJd5Mcl2R7VT2wtfaiGa0LAMCWNavDvi9Mcp8kByT59eUmrKoDkrwtya1Jjm6t/Upr7cVJHpLko0mOq6qnT9TZluR1GULiQ1trv9Fae2GSByX5pyQnV9UjZrQuAABb1kzCX2vtvNba51prbQWTH5fkR5Oc2Vr7+KJ53JShBzG5fYD85ST7JjmttbZzUZ1vJvm98e1z9rD5AADdmMcFH8eMww9NGXdBkhuSHFFV+66wzgcnpgEAYAmzOudvNe47Di+bHNFau6Wqrkhy/ySHJLl0BXWuqqrvJLlXVd25tXbDcguvqouXGLXseYoAAFvBPHr+DhyH1y4xfqH8LntQ58AlxgMAkPn0/M1Va+3waeVjj+Bh69wcAIB1NY+ev9310i2Uf2sP6izVMwgAQOYT/j47Du8zOaKq9klycJJbkly+wjr3SLJ/kit3d74fAEDv5hH+zh2Hj50y7sgkd05yUWvt5hXWedzENAAALGEe4e+9Sa5O8vSqeuhCYVXtl+R3xrdvnqjzjiQ3J3nueMPnhToHJXnZ+PYta9VgAICtYiYXfFTVsUmOHd/efRw+oqq2jz9fvfD4tdbadVX1qxlC4I6qOjPDkzuelOGWLu/N8Mi327TWrqiqFyd5U5KPV9W7suvxbvdK8oettY/OYl0AALayWV3t+5AkJ06UHTK+kuQLSW579m5r7ayqOirJy5M8Ncl+ST6f5DeTvGnak0Jaa6dW1c5xPr+YodfyH5O8orX2ZzNaDwCALW0m4a+1dkqSU1ZZ52+T/Mwq65yd5OzV1AEAYJd5nPMHAMCcCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCNzCX9V9cyqart53bpo+m27mfbMeawHAMBms8+clntJklcvMe6nkhyT5INTxn0yyVlTyj89k1YBAGxxcwl/rbVLMgTA26mqj44//smU0Ze01k5Zm1YBAGx9G+qcv6p6YJKHJ/lykg/MuTkAAFvOvA77LuXXxuHprbVbp4y/Z1U9O8ndknwjyUdba59at9YBAGxyGyb8VdWdkjwjya1J3r7EZD89vhbX25HkxNbaF1e4nIuXGHW/lbUUAGDz2kiHfX8uyV2SfKi19qWJcTck+e0khyc5aHwdleS8JEcn+XBV7b9uLQUA2KQ2TM9fdh3yfevkiNba15K8aqL4gqp6TJKPJHlYkmcleePuFtJaO3xa+dgjeNhqGgwAsNlsiJ6/qrp/kiOSXJnknJXWa63dkl2HiI9cg6YBAGwpGyL8ZfcXeizn6+PQYV8AgN2Ye/irqv2SnJDhQo/T92AWDx+Hl8+sUQAAW9Tcw1+S4zNcwPHBKRd6JEmq6rCqul1bq+rRSV44vj1j7ZoIALA1bIQLPhYO+U57oseC1ye5d1VdlOG8wCR5UIbHwCXJK1trF61R+wAAtoy5hr+qOjTJf8ruL/R4Z5KnJPmJJI9L8kNJvprk3UlOa61duMZNBQDYEuYa/lprlyapFUx3evbsfEAAABbZCOf8AQCwToQ/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANCRuYW/qtpZVW2J11eWqHNEVZ1TVddU1Y1V9amqOqmq7rje7QcA2Iz2mfPyr03yR1PKr58sqKonJ3lfkpuSvCvJNUmemOQNSR6Z5Pg1ayUAwBYx7/D3rdbaKbubqKoOSPK2JLcmObq19vGx/JVJzk1yXFU9vbV25lo2FgBgs9ss5/wdl+RHk5y5EPySpLV2U5JXjG9/fR4NAwDYTObd87dvVT0jyb9N8p0kn0pyQWvt1onpjhmHH5oyjwuS3JDkiKrat7V285q1FgBgk5t3+Lt7kndOlF1RVb/UWjt/Udl9x+FlkzNord1SVVckuX+SQ5JcutwCq+riJUbdb2VNBgDYvOZ52PcdSR6dIQDun+SBSd6aZFuSD1bVgxdNe+A4vHaJeS2U32XmrQQA2ELm1vPXWnv1RNGnkzynqq5PcnKSU5I8ZQ2We/i08rFH8LBZLw8AYCPZiBd8vGUcHrmobKFn78BMt1D+rbVoEADAVrERw9/Xx+H+i8o+Ow7vMzlxVe2T5OAktyS5fG2bBgCwuW3E8Pfwcbg4yJ07Dh87Zfojk9w5yUWu9AUAWN5cwl9VHVpV+08p35bktPHtGYtGvTfJ1UmeXlUPXTT9fkl+Z3z75rVpLQDA1jGvCz6eluTkqrogyReSfDvJjyd5fJL9kpyT5HULE7fWrquqX80QAndU1ZkZHu/2pAy3gXlvhke+AQCwjHmFv/MyhLb/mOG5vPtnuFjjIxnu+/fO1lpbXKG1dlZVHZXk5UmemiEkfj7JbyZ50+T0AADc3lzC33gD5/N3O+Ht6/1tkp+ZfYsAAPqwES/4AABgjQh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6Mg+824Am9e2l35g3k2YmZ2vffy8mwAA60LPHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR+YS/qrqblX1rKr6i6r6fFXdWFXXVtVHqupXquoOE9Nvq6q2zOvMeawHAMBms8+clnt8kjcnuSrJeUm+mOTHkvxskrcneVxVHd9aaxP1PpnkrCnz+/TaNRUAYOuYV/i7LMmTknygtfb9hcKqelmSf0jy1AxB8H0T9S5prZ2yXo0EANhq5nLYt7V2bmvt7MXBbyz/SpK3jG+PXveGAQBscfPq+VvO98bhLVPG3bOqnp3kbkm+keSjrbVPrVvLAAA2uQ0V/qpqnyS/OL790JRJfnp8La6zI8mJrbUvrnAZFy8x6n4rbCYAwKa10W718tokD0hyTmvtrxaV35Dkt5McnuSg8XVUhotFjk7y4araf32bCgCw+WyYnr+qen6Sk5N8JskJi8e11r6W5FUTVS6oqsck+UiShyV5VpI37m45rbXDl1j+xUkOW33LAQA2jw3R81dVz80Q3P4xyaNaa9espF5r7ZYMt4ZJkiPXqHkAAFvG3MNfVZ2U5NQM9+p71HjF72p8fRw67AsAsBtzDX9V9ZIkb0hySYbg97U9mM3Dx+Hls2oXAMBWNbfwV1WvzHCBx8VJHt1au3qZaQ+bfOTbWP7oJC8c356xJg0FANhC5nLBR1WdmOQ1SW5NcmGS51fV5GQ7W2vbx59fn+TeVXVRkivHsgclOWb8+ZWttYvWtNEAAFvAvK72PXgc3jHJSUtMc36S7ePP70zylCQ/keRxSX4oyVeTvDvJaa21C9eqoQAAW8lcwt/4fN5TVjH96UlOX6v2AAD0Yu5X+wIAsH6EPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR+b1eDfYULa99APzbsJM7Hzt4+fdBAA2OD1/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI7sM+8GALOz7aUfmHcTZmbnax8/7yYwxVbZx+xf9EzPHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BH3+QNYY1vl3nhbyVb6TNyzkNXS8wcA0BE9f8CGtJV6ZgA2Ej1/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0ZFOFv6q6V1X9aVX9c1XdXFU7q+qPquqgebcNAGAz2GfeDVipqvrxJBcl+VdJ3p/kM0l+MskLkjy2qh7ZWvvGHJsIAOyFbS/9wLybMDM7X/v4eTdhSZup5++/Zwh+z2+tHdtae2lr7Zgkb0hy3yS/O9fWAQBsApui52/s9XtMkp1J/nhi9H9L8mtJTqiqk1tr31nn5gHA3Gyl3jLWx2bp+XvUOPzr1tr3F49orX07yd8muXOSh693wwAANpNN0fOX4bBukly2xPjPZegZvE+SDy83o6q6eIlRD7700ktz+OGH71kLV+iqL1+7pvMHAObv8L951ZrO/9JLL02SbXtSd7OEvwPH4VLJaaH8LnuxjFtvvPHGaz/xiU/s3It57M79xuFn1nAZm4VtsYttsYttsYttsYttsYttscuG3haf+OqaL2Jbkuv2pOJmCX8z01pb2669ZSz0Os6zDRuFbbGLbbGLbbGLbbGLbbGLbbGLbbHnNss5fws9ewcuMX6h/Ftr3xQAgM1rs4S/z47D+ywx/t7jcKlzAgEAyOYJf+eNw8dU1Q+0uap+JMkjk9yQ5O/Wu2EAAJvJpgh/rbV/SvLXGU5u/I2J0a9Osn+Sd7rHHwDA8jbTBR//X4bHu72pqh6d5NIkD8twD8DLkrx8jm0DANgUqrU27zasWFX9mySvSfLYJHdLclWSv0jy6tbaN+fZNgCAzWBThT8AAPbOpjjnDwCA2RD+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwt86qKp7VdWfVtU/V9XNVbWzqv6oqg6ad9v2RFXdraqeVVV/UVWfr6obq+raqvpIVf3KlEfwbauqtszrzGWWdWJV/UNVXT8uY0dVPWHt13Llxs9zqXX7yhJ1jqiqc6rqmnH7faqqTqqqOy6znCeM63/tuD3+vqpOXLs1W72qeuZuPutWVbcumn7T7xtVdVxVnVpVF1bVdWO7z9hNnXX5/Nd7G61mW1TVvavqJVV1blV9qaq+W1Vfrar3V9Wjlqizu/3rOUvUu1NVvbqqPltVN1XV16rq3VV16CzXf2KZq9kW6/Y9qKo7VtULx33uxnEfPKeqjpjFei+xzNVsi+0r+B3y4Yk6m2a/2Cg20xM+NqWq+vEMTyb5V0nen+QzSX4yyQuSPLaqHtla+8Ycm7gnjk/y5gw32T4vyReT/FiSn03y9iSPq6rj2+1vIvnJJGdNmd+npy2kql6X5OQkVyZ5W5IfTvL0JGdX1fNaa6ft/arMzLVJ/mhK+fWTBVX15CTvS3JTkncluSbJE5O8IcNzqo+fUue5SU5N8o0kZyT5bpLjkmyvqge21l40k7XYe5dkeOTiND+V5JgkH5wybjPvG69I8uAMn/WVSe633MTr9fnPaRutZlv8dpKnJfnHJOdk2A73TfKkJE+qqhe01t60RN33Z9jXJn18sqCq9k3yNxm27ceTvDHJv8mwnR9fVce01v5+t2u2eqvaL0Zr+j2oqkpyZoZ957NJTkty1wyfwwVV9dTW2vtX0M7VWs22OCvJziXGnZDkkEz/HZJsjv1iY2itea3hK8lfJWlJnjdR/vqx/C3zbuMerNMxGf5Y3WGi/O4ZgmBL8tRF5dvGsu2rWMYRY53PJzloYl7fyPCHc9u8t8XYpp1Jdq5w2gOSfC3JzUkeuqh8vwz/JLQkT5+os21c328sXuckB43bpyV5xLy3wwrW/aNjW5+0lfaNDI+YvHeSSnL02LYz5vn5z2sbrXJbPDPJf5xSflSGcHtzkntMqdOSPHMVbfqtsc57suh3VpInj+X/LxO/y+awLdble5Dk58c6f5tkv0XlPzFu768l+ZF5botl5nGXJDeM7fyXm3W/2Cgvh33X0Njr95gM4eCPJ0b/tyTfSXJCVe2/zk3bK621c1trZ7fWvj9R/pUkbxnfHr2Xi1nopv/dtujRfa21nRm25b5JfmkvlzEPxyX50SRnttZu+2+0tXZThv+Ok+TXJ+r8cob1PW1c/4U630zye+PbqYc1NoqqemCShyf5cpIP7OXsNtS+0Vo7r7X2uTb+5diN9fr857KNVrMtWmvbW2v/Z0r5+Ul2ZOjF2qtDkWNP18K2+K+Lf2e1oYfrwiT/IUPgnKlV7hd7Yk8+44V96xXjPrdQ52MZeqF/NMM+OlMz2hYnJLlTkv/dWrt6b9ozz/1ioxD+1tbCeSt/PSUofTvDf193zvBHcav43ji8Zcq4e1bVs6vqZePwQcvM55hx+KEp4z44Mc1GsG9VPWNctxdU1aNq+vlby63XBRn+sz1iPCSxkjobcVtM82vj8PTW2q1Txm/lfWOx9fr8N/M2Spb/PZIkD6nhHMmXVtUJVXWvJab78ST/NsllrbUrpozfaNtizb4HVbVfhjB9Q4Zws9s6G8yvjsM/WWaarbpfzJxz/tbWfcfhZUuM/1yGnsH7JPnwEtNsGlW1T5JfHN9O+4X00+NrcZ0dSU5srX1xUdn+Sf51kutba1dNmc/nxuF99rbNM3T3JO+cKLuiqn5p7MlYsOQ+0Vq7paquSHL/DOe1XLqCOldV1XeS3Kuq7txau2FvVmItVNWdkjwjya0ZzgmdZivvG4ut+ee/2bdRVf27JI/OEFIuWGKyF0y8v7Wq3p7kpMU9WlnZ7+Bk42yLtfwe/HiSOya5vLU2LVRvtG1xm6p6RJIHZghr5y0z6VbdL2ZOz9/aOnAcXrvE+IXyu6x9U9bFa5M8IMk5rbW/WlR+Q4aTuw/PcJ7SQRm608/LcHj4wxOHvjfbdntHhj9Wd0+yf4ZfUm/NcO7NB6vqwYum3ZN1W2mdA5cYP28/l2F9PtRa+9LEuK2+b0xaj89/026jscfzf2Y4ZHnK4sOZoyuSPC/DH+/9k9wzw/61M8mzk/zpxPSbZVusx/dgs2yLaRaOHLxtifFbdb9YM8IfM1FVz89w1dlnMpybcZvW2tdaa69qrX2itfat8XVBhl7Pv0/y75M8a90bPSOttVeP50F+tbV2Q2vt062152S4qOdOSU6ZbwvnbuEX91snR2z1fYOVG0+TeGeGqy/fleR1k9O01s5vrZ3WWrts/K5d1Vp7T4ZTbL6Z5Ocn/tnaFHwPllZVB2YIct9Nsn3aNFt1v1hLwt/a2l2PzEL5t9a+KWtnvA3FGzPcsuFRrbVrVlJvPPSwcBjwyEWjtsp2W7j4ZW/XbaV1lvovdm6q6v4ZzjO6MsPtPFZkC+8b6/H5b7ptNAa/MzLcZuPdSZ6xmosDxh7lhf1ry+wvM/4ebNZt8YwM58av+kKPrbpfzILwt7Y+Ow6XOm/g3uNwqfMONryqOinD/cc+nSH4Tb2p8TK+Pg5vO6TRWvtOhqtC/0VV3WNKnc2y3W63bllmnxjPmTw4w0nul6+wzj3G+V+5Ec/3y+4v9FjOVtw31vzz32zbqKp+KMmfZ7g/3f9K8l+WOCdtd1b1fRttqG2xhFl9D/4pw3m3h4z72krqbAQLF3rc7sjBCm3V/WKvCH9ra+HE1MfU7Z968SMZDm/ckOTv1rths1BVL8lwY9pLMgS/r+3BbBaudL58ovzccfjYKXUeNzHNRjVt3ZZbryMz/Id7UWvt5hXW2bDbYry68IQMf3BO34NZbMV9Y70+/02xjarqhzPcZ+34JP8jyQl78E/CgoeNw8X7yz9luPfofarq4Cl1Nsy2WMZMvgfjBQ8XZdjHfmoldeatqh6W4ebQl7XWduzhbLbqfrF32ga42eBWfmUL3uR5bP8rx/Z/PMlddzPtYZlys8wMF0ncNM7niIlxG+pGvsus26FJ9p9Svi3DFWMtycsWlR+Q4T/R1dzk9+Bswps8Zwh+LcnZvewbWdlNntf8898I22gF22LfDPd8bBkObe72hrqLt9misjtk1w17v57kgInxc7+Z7wq2xbp8D7KymzwfsCfrOKttMTHt6eO0J2/F/WKerxpXljUy5fFul2b4T+RRGbqUj2ib7PFuNTxPdHuGHp1TM/1cs52tte3j9DsydKNflOHcryR5UHbdQ+mVrbXfmbKcP0zym2Od92a46evTktwtQ5ie++PdquqUDBe6XJDkC0m+neGWCo/P8Af9nCRPaa19d1GdYzOsz00ZHrV0TYZHWt13LP+5NvHFrKrnJXlThl/q78qux3vdK8kfto3zeLfbVNWFSf5Thid6nL3ENDuyyfeN8fM8dnx79yT/OUMvw8K91K5e/Pms1+c/j220mm1RVe/I8GSGq5P89wx/cCftaIt6fKqqZTjF5JMZDnsemOEIygMyHEV5SmvtryfatG+GHpwjMvyz+uEM93g7PsN2XJPHeK1yW+zIOnwPxpsbvzvDvvOZJGeP0z4tw++rNXm822q/I2OdA5L8c4Zb0t2rLXO+32baLzaMeafPHl4Znhf4jgzPwv1uhpDwR1n039pmemW4erXt5rVj0fS/kuQvM1x2f32G/zC/mOGP2E/tZlnPTPKxDE9D+XaS85M8Yd7bYFH7jspwvtJnMpwc/L0M/2X+TYZ7HtYS9R6ZIRh+M8mNSf5vkhcmueMyy3riuP7fHrfHxzLc/2vu22FKWw8d94Mv7WadNv2+sYLvw855ff7rvY1Wsy0yPMVjd79HTpmY/x+M6/DPGcLzDeN377QkhyzTrjsneU2G3vibx+/oe5L8hw2yLdbte5AhTL1w3OduHPfBczLRs7gBviO/Po778xXMf9PsFxvlpecPAKAjLvgAAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoyP8P5fwLQVkQn4IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 302,
       "width": 319
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# computing frequency of each note\n",
    "freq = dict(Counter(notes_))\n",
    "\n",
    "# consider only the frequencies\n",
    "no = [count for _, count in freq.items()]\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist(no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b307af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n"
     ]
    }
   ],
   "source": [
    "# filter out the notes that have a frequency lower than 50\n",
    "frequent_notes = [note_ for note_, count in freq.items() if count >= 50]\n",
    "print(len(frequent_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87619f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-0260187a6469>:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  new_music = np.array(new_music)\n"
     ]
    }
   ],
   "source": [
    "# filter out the notes with low frequency from the original data\n",
    "new_music = []\n",
    "\n",
    "for notes in notes_array:\n",
    "    temp = []\n",
    "    for note_ in notes:\n",
    "        if note_ in frequent_notes:\n",
    "            temp.append(note_)\n",
    "    new_music.append(temp)\n",
    "    \n",
    "new_music = np.array(new_music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d808ed3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for training\n",
    "# number of time steps\n",
    "no_timesteps = 32\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for note_ in new_music:\n",
    "    for i in range(0, len(note_) - no_timesteps, 1):\n",
    "        # preparing the input and outout sequence\n",
    "        input_ = note_[i: i + no_timesteps]\n",
    "        output_ = note_[i + no_timesteps]\n",
    "        \n",
    "        X.append(input_)\n",
    "        Y.append(output_)\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "922db30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76373, 32)\n",
      "(76373,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "557d65a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign unique integer to every note\n",
    "unique_X = list(set(X.ravel()))\n",
    "X_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_X))\n",
    "\n",
    "unique_Y = list(set(Y))\n",
    "Y_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0d133de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the input sequence\n",
    "X_seq = []\n",
    "for i in X:\n",
    "    temp = []\n",
    "    for j in i:\n",
    "        # convert notes to unique integers\n",
    "        temp.append(X_note_to_int[j])\n",
    "    X_seq.append(temp)\n",
    "\n",
    "X_seq = np.array(X_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34323d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the output note\n",
    "Y_seq = np.array([Y_note_to_int[i] for i in Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad0c2dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split 80/20\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_seq, Y_seq, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "788867d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61098, 32)\n",
      "(61098,)\n",
      "(15275, 32)\n",
      "(15275,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16778872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm():\n",
    "    \"\"\" LSTM model \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128,return_sequences=True))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6447a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 32, 100)           17600     \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 32, 64)            19264     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 16, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16, 128)           24704     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 8, 256)            98560     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 176)               45232     \n",
      "=================================================================\n",
      "Total params: 271,152\n",
      "Trainable params: 271,152\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# embedding layber\n",
    "model.add(Embedding(len(unique_X), 100, input_length = no_timesteps, trainable=True))\n",
    "\n",
    "model.add(Conv1D(64,3, padding='causal',activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "    \n",
    "model.add(Conv1D(128,3,activation='relu',dilation_rate=2,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "\n",
    "model.add(Conv1D(256,3,activation='relu',dilation_rate=4,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "          \n",
    "#model.add(Conv1D(256,5,activation='relu'))    \n",
    "model.add(GlobalMaxPool1D())\n",
    "    \n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(unique_Y), activation='softmax'))\n",
    "    \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "053f9f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "2 root error(s) found.\n  (0) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node sequential/conv1d/conv1d (defined at <ipython-input-18-ccd79b885d05>:9) ]]\n  (1) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node sequential/conv1d/conv1d (defined at <ipython-input-18-ccd79b885d05>:9) ]]\n\t [[gradient_tape/sequential/embedding/embedding_lookup/Reshape/_34]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_1348]\n\nFunction call stack:\ntrain_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ccd79b885d05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     )\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m history = model.fit(X_train,\n\u001b[0m\u001b[1;32m     10\u001b[0m                     \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/csslab-localdata/csslab-si/jack_working_dir/tutorial/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/csslab-localdata/csslab-si/jack_working_dir/tutorial/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/csslab-localdata/csslab-si/jack_working_dir/tutorial/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/csslab-localdata/csslab-si/jack_working_dir/tutorial/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/csslab-localdata/csslab-si/jack_working_dir/tutorial/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/csslab-localdata/csslab-si/jack_working_dir/tutorial/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/csslab-localdata/csslab-si/jack_working_dir/tutorial/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node sequential/conv1d/conv1d (defined at <ipython-input-18-ccd79b885d05>:9) ]]\n  (1) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node sequential/conv1d/conv1d (defined at <ipython-input-18-ccd79b885d05>:9) ]]\n\t [[gradient_tape/sequential/embedding/embedding_lookup/Reshape/_34]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_1348]\n\nFunction call stack:\ntrain_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = ModelCheckpoint(\n",
    "    \"wavenet_weights.hdf5\", \n",
    "    monitor='val_loss', \n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    "    )\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    Y_train,\n",
    "                    batch_size=128,\n",
    "                    epochs=50,\n",
    "                    validation_data=(X_val, Y_val),\n",
    "                    verbose=1,\n",
    "                    callbacks=[checkpoint_cb]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6d5d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trained model\n",
    "model = tf.keras.models.load_model('wavenet_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8704b190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "ind = np.random.randint(0,len(X_val)-1)\n",
    "\n",
    "random_music = X_val[ind]\n",
    "\n",
    "predictions=[]\n",
    "for i in range(100):\n",
    "\n",
    "    random_music = random_music.reshape(1,no_timesteps)\n",
    "\n",
    "    prob  = model.predict(random_music)[0]\n",
    "    y_pred= np.argmax(prob,axis=0)\n",
    "    predictions.append(y_pred)\n",
    "\n",
    "    random_music = np.insert(random_music[0],len(random_music[0]),y_pred)\n",
    "    random_music = random_music[1:]\n",
    "    \n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8a972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert prediction to notes\n",
    "X_int_to_note = dict((number, note_) for number, note_ in enumerate(unique_X)) \n",
    "predicted_notes = [X_int_to_note[i] for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cea8998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_midi(prediction_output):\n",
    "   \n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        \n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                \n",
    "                cn=int(current_note)\n",
    "                new_note = note.Note(cn)\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "                \n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "            \n",
    "        # pattern is a note\n",
    "        else:\n",
    "            \n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 1\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='wavenet_music.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724963b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_midi(predicted_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6145aa8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
