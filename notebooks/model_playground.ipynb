{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8712aaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pathlib\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from music21 import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\"\"\"\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Activation, Bidirectional, Flatten\n",
    "from keras import utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import applications\n",
    "from keras import datasets\n",
    "from keras import preprocessing\n",
    "from keras import wrappers\n",
    "from keras_self_attention import SeqSelfAttention # requires to use keras directly without tf \"\"\"\n",
    "\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from musiclearn import config\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6a072b",
   "metadata": {},
   "source": [
    "## Data Processing and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de25768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to Schubert collection\n",
    "schubert_dir = pathlib.Path(config.MUSICNET_MIDI_DIR) / \"Schubert\"\n",
    "\n",
    "# path to final fantasy collection\n",
    "ff_dir = pathlib.Path(config.FF_MIDI_DIR)\n",
    "\n",
    "# path to location of tensorboard logs\n",
    "logs_dir = pathlib.Path(config.LOGS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbe1ed5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of an input sequence\n",
    "SEQUENCE_LENGTH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3a7f8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes(midi_dir):\n",
    "    \"\"\" Get all the notes and chords from the midi files in a collection \"\"\"\n",
    "    notes = []\n",
    "    \n",
    "    noteFile_dir = str(midi_dir) + \"/notes\"\n",
    "    \n",
    "    if not os.path.exists(noteFile_dir):\n",
    "        files_dir = str(midi_dir) + \"/*.mid\"\n",
    "        for file in glob.glob(files_dir):\n",
    "            midi = converter.parse(file)\n",
    "\n",
    "            print(\"Parsing %s\" % file)\n",
    "\n",
    "            notes_to_parse = None\n",
    "\n",
    "            try: # file has instrument parts\n",
    "                s2 = instrument.partitionByInstrument(midi)\n",
    "                notes_to_parse = s2.parts[0].recurse()\n",
    "            except: # file has notes in a flat structure\n",
    "                notes_to_parse = midi.flat.notes\n",
    "\n",
    "            for element in notes_to_parse:\n",
    "                if isinstance(element, note.Note):\n",
    "                     notes.append(str(element.pitch))\n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "        # save the features\n",
    "        with open(noteFile_dir, 'wb') as fp:\n",
    "            pickle.dump(notes, fp)\n",
    "    else:\n",
    "        with open(noteFile_dir, 'rb') as fp:\n",
    "            notes = pickle.load(fp)\n",
    "    \n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "401c55d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_midi(midi_dir):\n",
    "    \"\"\" Read all midi file in the collection and return the notes \"\"\"\n",
    "    notes = []\n",
    "    \n",
    "    noteFile_dir = str(midi_dir) + \"/notes\"\n",
    "    \n",
    "    if not os.path.exists(noteFile_dir):\n",
    "        files_dir = str(midi_dir) + \"/*.mid\"\n",
    "        for file in glob.glob(files_dir):\n",
    "            midi = converter.parse(file)\n",
    "\n",
    "            print(\"Parsing %s\" % file)\n",
    "\n",
    "            notes_to_parse = None\n",
    "\n",
    "            try: # file has instrument parts\n",
    "                s2 = instrument.partitionByInstrument(midi)\n",
    "                \n",
    "                # looping over all the instrument parts\n",
    "                for part in s2.parts:\n",
    "                    #select elements of piano\n",
    "                    if \"Piano\" in str(part):\n",
    "                        notes_to_parse = part.recurse()\n",
    "            except: # file has notes in a flat structure\n",
    "                notes_to_parse = midi.flat.notes\n",
    "\n",
    "            # if there are notes to parse\n",
    "            if notes_to_parse is not None:\n",
    "                for element in notes_to_parse:\n",
    "                    if isinstance(element, note.Note):\n",
    "                         notes.append(str(element.pitch))\n",
    "                    elif isinstance(element, chord.Chord):\n",
    "                        notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "        # save the features\n",
    "        with open(noteFile_dir, 'wb') as fp:\n",
    "            pickle.dump(notes, fp)\n",
    "    else:\n",
    "        with open(noteFile_dir, 'rb') as fp:\n",
    "            notes = pickle.load(fp)\n",
    "    \n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29b75c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the notes\n",
    "#notes = get_notes(schubert_dir)\n",
    "notes = read_midi(schubert_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18d3b948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. unique notes = 312\n"
     ]
    }
   ],
   "source": [
    "# get the number of unique notes\n",
    "pitchNames = sorted(set(item for item in notes))\n",
    "n_vocab = len(pitchNames)\n",
    "print(\"No. unique notes =\", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e851b0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '0.1',\n",
       " '0.1.6',\n",
       " '0.2',\n",
       " '0.2.5',\n",
       " '0.2.5.8',\n",
       " '0.2.6',\n",
       " '0.2.6.8',\n",
       " '0.2.7',\n",
       " '0.3',\n",
       " '0.3.4',\n",
       " '0.3.5',\n",
       " '0.3.6',\n",
       " '0.3.6.8',\n",
       " '0.3.6.9',\n",
       " '0.3.7',\n",
       " '0.4',\n",
       " '0.4.5',\n",
       " '0.4.6',\n",
       " '0.4.7',\n",
       " '0.4.8',\n",
       " '0.5',\n",
       " '0.6',\n",
       " '1',\n",
       " '1.2',\n",
       " '1.2.6',\n",
       " '1.3',\n",
       " '1.3.6',\n",
       " '1.3.6.9',\n",
       " '1.3.7',\n",
       " '1.3.8',\n",
       " '1.4',\n",
       " '1.4.6',\n",
       " '1.4.7',\n",
       " '1.4.7.10',\n",
       " '1.4.7.9',\n",
       " '1.4.7.9.10',\n",
       " '1.4.8',\n",
       " '1.5',\n",
       " '1.5.7',\n",
       " '1.5.8',\n",
       " '1.5.9',\n",
       " '1.6',\n",
       " '1.7',\n",
       " '10',\n",
       " '10.0',\n",
       " '10.0.2',\n",
       " '10.0.3',\n",
       " '10.0.4',\n",
       " '10.0.5',\n",
       " '10.1',\n",
       " '10.1.3',\n",
       " '10.1.4',\n",
       " '10.1.4.5',\n",
       " '10.1.4.6',\n",
       " '10.1.5',\n",
       " '10.2',\n",
       " '10.2.3',\n",
       " '10.2.4',\n",
       " '10.2.5',\n",
       " '10.3',\n",
       " '11',\n",
       " '11.0',\n",
       " '11.0.4',\n",
       " '11.1',\n",
       " '11.1.4',\n",
       " '11.1.4.6',\n",
       " '11.1.4.7',\n",
       " '11.1.5',\n",
       " '11.1.6',\n",
       " '11.2',\n",
       " '11.2.4',\n",
       " '11.2.4.7',\n",
       " '11.2.5',\n",
       " '11.2.5.7',\n",
       " '11.2.6',\n",
       " '11.3',\n",
       " '11.3.5',\n",
       " '11.3.6',\n",
       " '11.4',\n",
       " '2',\n",
       " '2.3',\n",
       " '2.3.7',\n",
       " '2.4',\n",
       " '2.4.6',\n",
       " '2.4.7',\n",
       " '2.4.8',\n",
       " '2.4.8.9',\n",
       " '2.4.9',\n",
       " '2.5',\n",
       " '2.5.7',\n",
       " '2.5.8',\n",
       " '2.5.8.10',\n",
       " '2.5.8.11',\n",
       " '2.5.8.9',\n",
       " '2.5.9',\n",
       " '2.6',\n",
       " '2.6.10',\n",
       " '2.6.8',\n",
       " '2.6.9',\n",
       " '2.7',\n",
       " '2.7.8',\n",
       " '2.8',\n",
       " '3',\n",
       " '3.4',\n",
       " '3.5',\n",
       " '3.5.10',\n",
       " '3.5.9',\n",
       " '3.6',\n",
       " '3.6.10',\n",
       " '3.6.8',\n",
       " '3.6.9',\n",
       " '3.6.9.10',\n",
       " '3.6.9.11',\n",
       " '3.7',\n",
       " '3.7.10',\n",
       " '3.7.11',\n",
       " '3.7.9',\n",
       " '3.8',\n",
       " '3.9',\n",
       " '4',\n",
       " '4.10',\n",
       " '4.5',\n",
       " '4.5.10',\n",
       " '4.5.9',\n",
       " '4.6',\n",
       " '4.6.10',\n",
       " '4.6.11',\n",
       " '4.6.9',\n",
       " '4.6.9.0',\n",
       " '4.6.9.11',\n",
       " '4.7',\n",
       " '4.7.10',\n",
       " '4.7.10.0',\n",
       " '4.7.11',\n",
       " '4.7.8',\n",
       " '4.7.9',\n",
       " '4.8',\n",
       " '4.8.10',\n",
       " '4.8.11',\n",
       " '4.9',\n",
       " '5',\n",
       " '5.10',\n",
       " '5.11',\n",
       " '5.6.10',\n",
       " '5.6.9',\n",
       " '5.6.9.0',\n",
       " '5.7',\n",
       " '5.7.0',\n",
       " '5.7.10',\n",
       " '5.7.10.0',\n",
       " '5.7.11',\n",
       " '5.7.8',\n",
       " '5.7.9',\n",
       " '5.7.9.0',\n",
       " '5.8',\n",
       " '5.8.0',\n",
       " '5.8.10',\n",
       " '5.8.11',\n",
       " '5.8.11.1',\n",
       " '5.9',\n",
       " '5.9.0',\n",
       " '5.9.11',\n",
       " '6',\n",
       " '6.10',\n",
       " '6.10.0',\n",
       " '6.10.1',\n",
       " '6.11',\n",
       " '6.7',\n",
       " '6.8',\n",
       " '6.8.0',\n",
       " '6.8.0.1',\n",
       " '6.8.1',\n",
       " '6.8.11',\n",
       " '6.9',\n",
       " '6.9.0',\n",
       " '6.9.0.2',\n",
       " '6.9.1',\n",
       " '6.9.11',\n",
       " '7',\n",
       " '7.0',\n",
       " '7.10',\n",
       " '7.10.0',\n",
       " '7.10.0.3',\n",
       " '7.10.1',\n",
       " '7.10.1.3',\n",
       " '7.10.2',\n",
       " '7.11',\n",
       " '7.11.1',\n",
       " '7.11.2',\n",
       " '7.8',\n",
       " '7.8.0',\n",
       " '7.8.11',\n",
       " '7.9',\n",
       " '7.9.0',\n",
       " '7.9.0.2',\n",
       " '7.9.0.3',\n",
       " '7.9.1',\n",
       " '7.9.10',\n",
       " '7.9.2',\n",
       " '8',\n",
       " '8.0',\n",
       " '8.0.1',\n",
       " '8.0.2',\n",
       " '8.0.3',\n",
       " '8.1',\n",
       " '8.10',\n",
       " '8.10.0',\n",
       " '8.10.0.3',\n",
       " '8.10.1',\n",
       " '8.10.1.4',\n",
       " '8.10.2',\n",
       " '8.10.3',\n",
       " '8.11',\n",
       " '8.11.1',\n",
       " '8.11.2',\n",
       " '8.11.2.4',\n",
       " '8.11.3',\n",
       " '8.9',\n",
       " '9',\n",
       " '9.0',\n",
       " '9.0.2',\n",
       " '9.0.3',\n",
       " '9.0.3.5',\n",
       " '9.0.4',\n",
       " '9.1',\n",
       " '9.1.3',\n",
       " '9.1.4',\n",
       " '9.10',\n",
       " '9.10.2',\n",
       " '9.11',\n",
       " '9.11.2',\n",
       " '9.11.2.5',\n",
       " '9.11.3',\n",
       " '9.11.4',\n",
       " '9.2',\n",
       " 'A1',\n",
       " 'A2',\n",
       " 'A3',\n",
       " 'A4',\n",
       " 'A5',\n",
       " 'A6',\n",
       " 'B-1',\n",
       " 'B-2',\n",
       " 'B-3',\n",
       " 'B-4',\n",
       " 'B-5',\n",
       " 'B-6',\n",
       " 'B1',\n",
       " 'B2',\n",
       " 'B3',\n",
       " 'B4',\n",
       " 'B5',\n",
       " 'B6',\n",
       " 'C#2',\n",
       " 'C#3',\n",
       " 'C#4',\n",
       " 'C#5',\n",
       " 'C#6',\n",
       " 'C#7',\n",
       " 'C2',\n",
       " 'C3',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C6',\n",
       " 'C7',\n",
       " 'D1',\n",
       " 'D2',\n",
       " 'D3',\n",
       " 'D4',\n",
       " 'D5',\n",
       " 'D6',\n",
       " 'D7',\n",
       " 'E-2',\n",
       " 'E-3',\n",
       " 'E-4',\n",
       " 'E-5',\n",
       " 'E-6',\n",
       " 'E-7',\n",
       " 'E1',\n",
       " 'E2',\n",
       " 'E3',\n",
       " 'E4',\n",
       " 'E5',\n",
       " 'E6',\n",
       " 'E7',\n",
       " 'F#1',\n",
       " 'F#2',\n",
       " 'F#3',\n",
       " 'F#4',\n",
       " 'F#5',\n",
       " 'F#6',\n",
       " 'F1',\n",
       " 'F2',\n",
       " 'F3',\n",
       " 'F4',\n",
       " 'F5',\n",
       " 'F6',\n",
       " 'F7',\n",
       " 'G#1',\n",
       " 'G#2',\n",
       " 'G#3',\n",
       " 'G#4',\n",
       " 'G#5',\n",
       " 'G#6',\n",
       " 'G#7',\n",
       " 'G1',\n",
       " 'G2',\n",
       " 'G3',\n",
       " 'G4',\n",
       " 'G5',\n",
       " 'G6']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pitchNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd1f69af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary to map notes to unique integers\n",
    "note_to_int = dict((note, number) for number, note in enumerate(pitchNames))\n",
    "\n",
    "# create a dictionary to map unique integers to notes\n",
    "int_to_note = dict((number, note) for number, note in enumerate(pitchNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c25ea6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(sequence_length, notes, n_vocab, note_to_int):\n",
    "    \"\"\" Prepare the sequences used by the neural network \"\"\"   \n",
    "    network_input = []\n",
    "    network_output = []\n",
    "    \n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i : i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "        \n",
    "    n_samples = len(network_input)\n",
    "    \n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    network_input = np.reshape(network_input, (n_samples, sequence_length, 1))\n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "    \n",
    "    network_output = np.array(network_output)\n",
    "    \n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f92ba50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78937, 100, 1)\n",
      "(78937,)\n"
     ]
    }
   ],
   "source": [
    "# test prepare_sequences()\n",
    "network_input, network_output = prepare_sequences(SEQUENCE_LENGTH, notes, n_vocab, note_to_int)\n",
    "print(network_input.shape)\n",
    "print(network_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2285669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_midi(notes_list, filename):\n",
    "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
    "        from the notes \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in notes_list:\n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        # pattern is a note\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 1\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "\n",
    "    midi_stream.write('midi', fp=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acfabb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm_model(model, sequence_length, notes, n_vocab, note_to_int, model_name, epochs=20, batch_size=128):\n",
    "    \"\"\" Train a neural network to generate music \"\"\"\n",
    "    # get amount of pitch names\n",
    "    n_vocab = len(set(notes))\n",
    "    \n",
    "    network_input, network_output = prepare_sequences(sequence_length, notes, n_vocab, note_to_int)\n",
    "\n",
    "    #model = lstm_model(network_input.shape, n_vocab)\n",
    "    \n",
    "    # train the network\n",
    "    filepath = model_name + \"_saved_weight.hdf5\"\n",
    "    \n",
    "    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath,\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        node='min'\n",
    "    )\n",
    "    \n",
    "    log_dir = str(logs_dir / \"logs\" / model_name)\n",
    "    tensorboard_cb = TensorBoard(log_dir=log_dir,\n",
    "                                     write_graph=True,\n",
    "                                     write_images=True,\n",
    "                                     update_freq='epoch'\n",
    "                                )\n",
    "    \n",
    "    callback_list = [checkpoint_cb, tensorboard_cb]\n",
    "    \n",
    "    model.fit(network_input, \n",
    "              network_output, \n",
    "              epochs=epochs, \n",
    "              batch_size=batch_size, \n",
    "              callbacks=callback_list,\n",
    "              validation_split=0.2\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "116b8366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_notes(model, network_input, int_to_note, n_vocab):\n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # pick a random sequence from the input as a starting point for the prediction\n",
    "    start = np.random.randint(0, len(network_input)-1)\n",
    "\n",
    "    pattern = network_input[start]\n",
    "    prediction_output = []\n",
    "\n",
    "    # generate 500 notes\n",
    "    for note_index in range(500):\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "\n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "\n",
    "        index = np.argmax(prediction)\n",
    "        result = int_to_note[index]\n",
    "        prediction_output.append(result)\n",
    "\n",
    "        #pattern.append(index)\n",
    "        pattern = np.append(pattern, [index])\n",
    "        pattern = pattern[1:]\n",
    "\n",
    "    return prediction_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0937f6bf",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bec718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(input_shape, n_vocab):\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(input_shape[1], input_shape[2]),\n",
    "        return_sequences=True\n",
    "    ))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add((LSTM(512, return_sequences=True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(512))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6652b3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cc0ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test code to output model architecture\n",
    "network_input, network_output = prepare_sequences(SEQUENCE_LENGTH, notes, n_vocab, note_to_int)\n",
    "lstm_model = lstm_model(network_input.shape, n_vocab)\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7003852",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "train_lstm_model(lstm_model, SEQUENCE_LENGTH, notes, n_vocab, note_to_int, \"lstm\", 100, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2d21b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lstm_model():\n",
    "    \"\"\" Load the saved LSTM model \"\"\"\n",
    "    \n",
    "    model = tf.keras.models.load_model('lstm_saved_weight.hdf5')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d9ed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a new midi file from the train model\n",
    "noteFile_dir = str(schubert_dir / \"notes\")\n",
    "    \n",
    "# load the notes used to train the model\n",
    "with open(noteFile_dir, 'rb') as fp:\n",
    "    notes = pickle.load(fp)\n",
    "\n",
    "network_input, _ = prepare_sequences(SEQUENCE_LENGTH, notes, n_vocab, note_to_int)\n",
    "print(network_input[0].shape)\n",
    "    \n",
    "# load saved weights\n",
    "model = load_lstm_model()\n",
    "\n",
    "# generate a new sequence\n",
    "prediction_output = generate_notes(model, network_input, int_to_note, n_vocab)\n",
    "\n",
    " # make midi file\n",
    "create_midi(prediction_output, \"lstm_output_sample.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8b0427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27d7be5a",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c38b59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bidirectional_lstm_model(input_shape, n_vocab):\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(512, return_sequences=True), input_shape=(input_shape[1], input_shape[2])))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Bidirectional(LSTM(512, return_sequences=True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Bidirectional(LSTM(512)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64806e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496fbd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test code to output model architecture\n",
    "network_input, network_output = prepare_sequences(SEQUENCE_LENGTH, notes, n_vocab, note_to_int)\n",
    "bidirectional_lstm_model = bidirectional_lstm_model(network_input.shape, n_vocab)\n",
    "bidirectional_lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd7ed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "train_lstm_model(bidirectional_lstm_model, SEQUENCE_LENGTH, notes, n_vocab, note_to_int, \"bidirect_lstm\", 100, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb507c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bidirectional_lstm_model():\n",
    "    \"\"\" Load the saved LSTM model \"\"\"\n",
    "    \n",
    "    model = tf.keras.models.load_model('bidirect_lstm_saved_weight.hdf5')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e818ff36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a new midi file from the train model\n",
    "noteFile_dir = str(schubert_dir / \"notes\")\n",
    "    \n",
    "# load the notes used to train the model\n",
    "with open(noteFile_dir, 'rb') as fp:\n",
    "    notes = pickle.load(fp)\n",
    "\n",
    "network_input, _ = prepare_sequences(SEQUENCE_LENGTH, notes, n_vocab, note_to_int)\n",
    "print(network_input[0].shape)\n",
    "    \n",
    "# load saved weights\n",
    "model = load_bidirectional_lstm_model()\n",
    "\n",
    "# generate a new sequence\n",
    "prediction_output = generate_notes(model, network_input, int_to_note, n_vocab)\n",
    "\n",
    " # make midi file\n",
    "create_midi(prediction_output, \"bidirect_lstm_output_sample.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7c7ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130332ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "533a372b",
   "metadata": {},
   "source": [
    "## LSTM with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd211328",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customized_Attention(Layer):\n",
    "    \"\"\" Attention block \"\"\"\n",
    "    def __init__(self, return_sequences=True):\n",
    "        self.return_sequences=return_sequences\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.W=self.add_weight(name=\"att_weight\", shape=(input_shape[-1],1),\n",
    "                               initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1],1),\n",
    "                               initializer=\"zeros\")\n",
    "        super().build(input_shape)\n",
    "        \n",
    "        \n",
    "    def call(self, x):\n",
    "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
    "        a = K.softmax(e, axis=1)\n",
    "        output = x * a\n",
    "        \n",
    "        if self.return_sequences:\n",
    "            return output\n",
    "        return K.sum(output, axis=1)\n",
    "    \n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({'return_sequences': self.return_sequences})\n",
    "        return config\n",
    "    \n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a6d4b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_lstm_model(input_shape, n_vocab):\n",
    "    \"\"\" Construct a model based on LSTM and attention \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Bidirectional LSTM layer with attention\n",
    "    model.add(Bidirectional(LSTM(512, return_sequences=True), \n",
    "                            input_shape=(input_shape[1], input_shape[2])\n",
    "                           )\n",
    "             )\n",
    "    model.add(Customized_Attention(return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    # Second bidirectional LSTM layer with attention\n",
    "    model.add(Bidirectional(LSTM(512, return_sequences=True)))\n",
    "    model.add(Customized_Attention(return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(512)))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    # compile\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9aecffd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "524a1278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, 100, 1024)         2105344   \n",
      "_________________________________________________________________\n",
      "customized__attention (Custo (None, 100, 1024)         1124      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100, 1024)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 100, 1024)         6295552   \n",
      "_________________________________________________________________\n",
      "customized__attention_1 (Cus (None, 100, 1024)         1124      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 1024)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 1024)              6295552   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 312)               80184     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 312)               0         \n",
      "=================================================================\n",
      "Total params: 15,041,280\n",
      "Trainable params: 15,041,280\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# test the architecture\n",
    "network_input, network_output = prepare_sequences(SEQUENCE_LENGTH, notes, n_vocab, note_to_int)\n",
    "attention_lstm_model = attention_lstm_model(network_input.shape, n_vocab)\n",
    "attention_lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392acc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(attention_lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a508c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "train_lstm_model(attention_lstm_model, SEQUENCE_LENGTH, notes, n_vocab, note_to_int, \"attention_lstm\", 100, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f724168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_attention_lstm_model(input_shape, n_vocab):\n",
    "    \"\"\" Load the saved weights \"\"\"\n",
    "    #model = tf.keras.models.load_model(\"attention_lstm_saved_weight.hdf5\")\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # Bidirectional LSTM layer with attention\n",
    "    model.add(Bidirectional(LSTM(512, return_sequences=True), \n",
    "                            input_shape=(input_shape[1], input_shape[2])\n",
    "                           )\n",
    "             )\n",
    "    model.add(Customized_Attention(return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    # Second bidirectional LSTM layer with attention\n",
    "    model.add(Bidirectional(LSTM(512, return_sequences=True)))\n",
    "    model.add(Customized_Attention(return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(512)))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    # compile\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
    "    \n",
    "    model.load_weights(\"attention_lstm_saved_weight.hdf5\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f12d871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "# generate a new midi file from the train model\n",
    "noteFile_dir = str(schubert_dir / \"notes\")\n",
    "    \n",
    "# load the notes used to train the model\n",
    "with open(noteFile_dir, 'rb') as fp:\n",
    "    notes = pickle.load(fp)\n",
    "\n",
    "network_input, _ = prepare_sequences(SEQUENCE_LENGTH, notes, n_vocab, note_to_int)\n",
    "print(network_input[0].shape)\n",
    "    \n",
    "# load saved weights\n",
    "model = load_attention_lstm_model(network_input.shape, n_vocab)\n",
    "\n",
    "# generate a new sequence\n",
    "prediction_output = generate_notes(model, network_input, int_to_note, n_vocab)\n",
    "\n",
    " # make midi file\n",
    "create_midi(prediction_output, \"attention_lstm_output_sample.mid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb0ed0c",
   "metadata": {},
   "source": [
    "## WaveNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d8163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d584fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplified_wavenet(n_vocab, sequence_length):\n",
    "    \"\"\" A simplified version of WaveNet without residual and skip connection \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # embedding layer\n",
    "    model.add(Embedding(n_vocab, 100, input_length=sequence_length))\n",
    "    \n",
    "    # causal convolution\n",
    "    model.add(Conv1D(64, 3, padding='causal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPool1D(2))\n",
    "    \n",
    "    # dialated causal convolution\n",
    "    model.add(Conv1D(128,3,activation='relu',dilation_rate=2,padding='causal'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPool1D(2))\n",
    "\n",
    "    model.add(Conv1D(256,3,activation='relu',dilation_rate=4,padding='causal'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPool1D(2))\n",
    "    \n",
    "    #model.add(Conv1D(256,5,activation='relu'))    \n",
    "    model.add(GlobalMaxPool1D())\n",
    "    \n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(n_vocab, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebf906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WaveNetResidualConv1D(num_filters, kernel_size, dilation_rate):\n",
    "    \"\"\" Function that creates a residual block for the WaveNet with gated\n",
    "        activation units, skip connections and residual output, as described\n",
    "        in Sections 2.3 and 2.4 of the paper [1].\n",
    "        Args:\n",
    "            num_filters (int): Number of filters used for convolution.\n",
    "            kernel_size (int): The size of the convolution.\n",
    "            dilation_rate (int): The dilation rate for the dilated convolution.\n",
    "        Returns:\n",
    "            A layer wrapper compatible to the Keras functional API.\n",
    "        See:\n",
    "            [1] Oord, Aaron van den, et al. \"Wavenet: A generative model for\n",
    "                raw audio.\" arXiv preprint arXiv:1609.03499 (2016).\n",
    "    \"\"\"\n",
    "    def build_residual_block(l_input):\n",
    "        # Gated activation.\n",
    "        l_sigmoid_conv1d = Conv1D(num_filters, kernel_size, dilation_rate=dilation_rate, \n",
    "                                  padding=\"same\", activation=\"sigmoid\")(l_input)\n",
    "        l_tanh_conv1d = Conv1D(num_filters, kernel_size, dilation_rate=dilation_rate,\n",
    "                               padding=\"same\", activation=\"tanh\")(l_input)\n",
    "        l_mul = Multiply()([l_sigmoid_conv1d, l_tanh_conv1d])\n",
    "        # Branches out to skip unit and residual output.\n",
    "        l_skip_connection = Conv1D(1, 1)(l_mul)\n",
    "        l_residual = Add()([l_input, l_skip_connection])\n",
    "        return l_residual, l_skip_connection\n",
    "    \n",
    "    return build_residual_block\n",
    "\n",
    "\n",
    "def build_wavenet_model(input_size, num_filters, kernel_size,\n",
    "                        num_residual_blocks):\n",
    "    \"\"\" Returns an implementation of WaveNet, as described in Section 2\n",
    "        of the paper [1].\n",
    "        Args:\n",
    "            input_size (int): The size of the waveform the network will\n",
    "                consider as input.\n",
    "            num_filters (int): Number of filters used for convolution.\n",
    "            kernel_size (int): The size of the convolution.\n",
    "            num_residual_blocks (int): How many residual blocks to generate\n",
    "                between input and output. Residual block i will have a dilation\n",
    "                rate of 2^(i+1), i starting from zero.\n",
    "        Returns:\n",
    "            A Keras model representing the WaveNet.\n",
    "        See:\n",
    "            [1] Oord, Aaron van den, et al. \"Wavenet: A generative model for\n",
    "                raw audio.\" arXiv preprint arXiv:1609.03499 (2016).\n",
    "    \"\"\"\n",
    "    l_input = Input(batch_shape=(None, input_size, 1))\n",
    "    l_stack_conv1d = Conv1D(num_filters, kernel_size, padding=\"same\")(l_input)\n",
    "    l_skip_connections = []\n",
    "    for i in range(num_residual_blocks):\n",
    "        l_stack_conv1d, l_skip_connection = WaveNetResidualConv1D(\n",
    "            num_filters, kernel_size, 2 ** (i + 1))(l_stack_conv1d)\n",
    "        l_skip_connections.append(l_skip_connection)\n",
    "    l_sum = Add()(l_skip_connections)\n",
    "    relu = Activation(\"relu\")(l_sum)\n",
    "    l1_conv1d = Conv1D(1, 1, activation=\"relu\")(relu)\n",
    "    l2_conv1d = Conv1D(1, 1)(l1_conv1d)\n",
    "    l_flatten = Flatten()(l2_conv1d)\n",
    "    l_output = Dense(256, activation=\"softmax\")(l_flatten)\n",
    "    model = Model(inputs=[l_input], outputs=[l_output])\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7825a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavenet_model = simplified_wavenet(n_vocab, SEQUENCE_LENGTH)\n",
    "wavenet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a85d0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences_wavenet(sequence_length, notes, n_vocab, note_to_int):\n",
    "    \"\"\" Prepare the sequences used by the neural network \"\"\"   \n",
    "    network_input = []\n",
    "    network_output = []\n",
    "    \n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i : i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "        \n",
    "    n_samples = len(network_input)\n",
    "    \n",
    "    # no reshape\n",
    "    network_input = np.array(network_input)\n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "    \n",
    "    network_output = np.array(network_output)\n",
    "    \n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a6e9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the input to the model\n",
    "X, Y = prepare_sequences_wavenet(SEQUENCE_LENGTH, notes, n_vocab, note_to_int)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49f8987",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9765435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c058db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = ModelCheckpoint(\n",
    "    \"wavenet_weights.hdf5\", \n",
    "    monitor='val_loss', \n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    "    )\n",
    "\n",
    "log_dir = str(logs_dir / \"logs\" / 'wavenet')\n",
    "tensorboard_cb = TensorBoard(log_dir=log_dir,\n",
    "                                 write_graph=True,\n",
    "                                 write_images=True,\n",
    "                                 update_freq='epoch'\n",
    "                            )\n",
    "\n",
    "history = wavenet_model.fit(X_train,\n",
    "                    Y_train,\n",
    "                    batch_size=128,\n",
    "                    epochs=100,\n",
    "                    validation_data=(X_val, Y_val),\n",
    "                    verbose=1,\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7790e771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wavenet_model():\n",
    "    \"\"\" Load the saved weights of the WaveNet model \"\"\"\n",
    "    model = tf.keras.models.load_model('wavenet_weights.hdf5')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f16ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trained model\n",
    "wavenet_model = load_wavenet_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f031ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_notes(model, network_input, int_to_note, n_vocab):\n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # pick a random sequence from the input as a starting point for the prediction\n",
    "    start = np.random.randint(0, len(network_input)-1)\n",
    "\n",
    "    pattern = list(network_input[start])\n",
    "    prediction_output = []\n",
    "\n",
    "    # generate 500 notes\n",
    "    for note_index in range(500):\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern)))\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "\n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "\n",
    "        index = np.argmax(prediction)\n",
    "        result = int_to_note[index]\n",
    "        prediction_output.append(result)\n",
    "\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:]\n",
    "\n",
    "    return prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873a3a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate new sequence with wavenet\n",
    "predicted_notes = generate_notes(wavenet_model, X_val, int_to_note, n_vocab)\n",
    "\n",
    "# convert to MiDi file\n",
    "create_midi(predicted_notes, \"wavenet_sample_output.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf966b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
