{"cells":[{"cell_type":"markdown","metadata":{},"source":[" # MIDI Model Playground\n","\n"," An exploratory notebook for playing with model architecture ideas."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pathlib\n","import sys\n","import numpy as np\n","import pypianoroll\n","import matplotlib.pyplot as plt\n","from tensorflow.keras import utils, layers, Model, optimizers, Sequential\n","\n","sys.path.append(\"..\")\n","from musiclearn import config\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Picking one song from MusicNet dataset\n","midi_dir = pathlib.Path(config.MUSICNET_MIDI_DIR)\n","mid_2494 = midi_dir / \"Beethoven\" / \"2494_qt11_1.mid\"\n","multitrack = pypianoroll.read(mid_2494, resolution=24)\n",""]},{"cell_type":"markdown","metadata":{},"source":["\n"," ## Training data representation\n","\n"," Because an entire song is too long music is generally composed in bars or\n"," multi-bar phrases, we plan to read MIDI files and segment them into phrases,\n"," one training example per phrase."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_num_beats(multitrack, resolution):\n","    return len(multitrack.downbeat) // resolution\n","\n","\n","def get_bar_bounds(bar_index, num_bars, beats_per_bar, resolution):\n","    start = bar_index * resolution\n","    end = start + (num_bars * beats_per_bar) * resolution\n","    return (start, end)\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def bars(multitrack, start_index, num_bars, beats_per_bar, resolution):\n","    start, end = get_bar_bounds(start_index, num_bars, beats_per_bar, resolution)\n","    tracks = []\n","    for track in multitrack.tracks:\n","        tracks.append(\n","            pypianoroll.Track(\n","                name=track.name,\n","                program=track.program,\n","                pianoroll=track[start:end],\n","            )\n","        )\n","    return pypianoroll.Multitrack(tracks=tracks, resolution=resolution)\n","\n",""]},{"cell_type":"markdown","metadata":{},"source":[" Plot a bar of Beethoven:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["resolution = 24\n","first_bar = bars(multitrack, 0, 1, 4, resolution)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["viola_track = first_bar.tracks[2]\n",""]},{"cell_type":"markdown","metadata":{},"source":["\n"," ## Pianoroll sequence autoencoder model\n","\n"," Testing out training a simple autoencoder model on a single track."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Prepare training examples from the binarized cello track\n","resolution = 24\n","beats_per_bar = 4\n","bars_per_phrase = 2\n","total_bars = get_num_beats(multitrack, resolution) // beats_per_bar\n","total_phrases = total_bars // bars_per_phrase\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["viola_clips = [\n","    bars(\n","        multitrack,\n","        i * bars_per_phrase,\n","        bars_per_phrase,\n","        beats_per_bar,\n","        resolution,\n","    )\n","    .tracks[2]\n","    .binarize()\n","    .pianoroll.astype(int)\n","    for i in range(total_phrases)\n","]\n","np_viola = np.array(viola_clips)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["np_viola\n",""]},{"cell_type":"markdown","metadata":{},"source":["\n"," The viola only plays notes 48-70, notes outside this range are all zeroes\n"," We can trim the note space to reduce dimensionality and avoid the model trying\n"," to fit notes outside the viola's range."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["np_viola.sum(axis=(0, 1))\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["np_viola = np_viola[:, :, 48:70]\n","np_viola.sum(axis=(0, 1))\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# make the features ordinal\n","# np_viola = np.argmax(np_viola, axis=2).astype(float)\n","# np_viola = np_viola.reshape(np_viola.shape[0], np_viola.shape[1], 1)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["np_viola\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["n_timesteps = np_viola.shape[1]\n","n_features = np_viola.shape[2]\n","shape = (n_timesteps, n_features)\n","print(shape)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["opt = optimizers.Adam(learning_rate=0.0001)\n","act = \"tanh\"\n","model = Sequential()\n","model.add(\n","    layers.LSTM(\n","        512,\n","        activation=\"tanh\",\n","        input_shape=(n_timesteps, n_features),\n","        return_sequences=True,\n","    )\n",")\n","model.add(layers.LSTM(128, activation=act, return_sequences=True))\n","model.add(layers.LSTM(128, activation=act, return_sequences=True))\n","model.add(layers.LSTM(512, activation=act, return_sequences=True))\n","model.add(layers.TimeDistributed(layers.Dense(n_features, activation=\"softmax\")))\n","model.compile(\n","    optimizer=opt,\n","    # loss=\"categorical_crossentropy\",\n","    loss=\"kullback_leibler_divergence\",\n","    metrics=[\"categorical_accuracy\"],\n",")\n","# utils.plot_model(model, show_shapes=True)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["history = model.fit(np_viola, np_viola, epochs=500)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["yhat = model.predict(np_viola)\n","yhat[0, :, 0]\n","preds = (yhat > 0.5).astype(int)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["np.argmax(preds[0, :, :], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["np.argmax(np_viola[0, :, :], axis=1)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":2}}